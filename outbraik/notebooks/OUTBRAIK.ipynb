{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#Dummy-data\" data-toc-modified-id=\"Dummy-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Dummy data</a></span></li><li><span><a href=\"#Cross-validation\" data-toc-modified-id=\"Cross-validation-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Cross-validation</a></span></li><li><span><a href=\"#Create-Tensorflow-DNN-model\" data-toc-modified-id=\"Create-Tensorflow-DNN-model-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Create Tensorflow DNN model</a></span></li><li><span><a href=\"#Bayesian-optimisation\" data-toc-modified-id=\"Bayesian-optimisation-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Bayesian optimisation</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nodos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wilsonwu/anaconda3/envs/freesolv/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# General:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import time\n",
    "import shutil\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "# Tensorflow:\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Scikit-Optimise\n",
    "from skopt import gp_minimize, dump\n",
    "from skopt.space import Categorical, Integer\n",
    "from skopt.utils import use_named_args\n",
    "from skopt.plots import plot_convergence\n",
    "\n",
    "# Statistics:\n",
    "import scipy\n",
    "from uncertainties import unumpy\n",
    "import itertools\n",
    "import statistics\n",
    "itertools.imap = lambda *args, **kwargs: list(map(*args, **kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Death cases</th>\n",
       "      <th>Infected cases</th>\n",
       "      <th>Period of time (months)</th>\n",
       "      <th>Population density inhab/km3</th>\n",
       "      <th>Population</th>\n",
       "      <th>GDP (trillion USD)</th>\n",
       "      <th>Infected rate</th>\n",
       "      <th>Mortality rate</th>\n",
       "      <th>Temperature C (1st month)</th>\n",
       "      <th>Humidity %(1st month)</th>\n",
       "      <th>Epidemic or not</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disease</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2002 SARS China</td>\n",
       "      <td>Guangzhou</td>\n",
       "      <td>774.0</td>\n",
       "      <td>8090.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1128.0</td>\n",
       "      <td>8392000.0</td>\n",
       "      <td>1471.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>9.57</td>\n",
       "      <td>19.4</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2008 HFMD China</td>\n",
       "      <td>Fuyang</td>\n",
       "      <td>431.0</td>\n",
       "      <td>1520274.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>728000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>208,83</td>\n",
       "      <td>0.03</td>\n",
       "      <td>9.2</td>\n",
       "      <td>79.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2009 Meningitis West Africa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>4.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2009 Influenza Mexico</td>\n",
       "      <td>Veracruz</td>\n",
       "      <td>395600.0</td>\n",
       "      <td>200000000.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>800000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25000,00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2012 MERS Saudi Arabia</td>\n",
       "      <td>Jeddah</td>\n",
       "      <td>449.0</td>\n",
       "      <td>1123.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>39.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2015 Influenza India</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>2035.0</td>\n",
       "      <td>33761.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>6.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019 Measles Samoa</td>\n",
       "      <td>Samoa</td>\n",
       "      <td>83.0</td>\n",
       "      <td>5707.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>1.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019 Measles Tonga</td>\n",
       "      <td>Tongatapu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>612.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019 Measles Rep. Of the Congo</td>\n",
       "      <td>Brazzaville</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>2.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019 Novel Coronavirus</td>\n",
       "      <td>Wuhan</td>\n",
       "      <td>724.0</td>\n",
       "      <td>34964.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>2.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018 HFMD Malaysia</td>\n",
       "      <td>Kuching</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#DIV/0!</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Region  Death cases  Infected cases  \\\n",
       "Disease                                                                    \n",
       "2002 SARS China                   Guangzhou        774.0          8090.0   \n",
       "2008 HFMD China                      Fuyang        431.0       1520274.0   \n",
       "2009 Meningitis West Africa             NaN       1100.0         25000.0   \n",
       "2009 Influenza Mexico              Veracruz     395600.0     200000000.0   \n",
       "2012 MERS Saudi Arabia               Jeddah        449.0          1123.0   \n",
       "2015 Influenza India              Rajasthan       2035.0         33761.0   \n",
       "2019 Measles Samoa                    Samoa         83.0          5707.0   \n",
       "2019 Measles Tonga                Tongatapu          0.0           612.0   \n",
       "2019 Measles Rep. Of the Congo  Brazzaville       6000.0        250000.0   \n",
       "2019 Novel Coronavirus                Wuhan        724.0         34964.0   \n",
       "2018 HFMD Malaysia                  Kuching          2.0         50000.0   \n",
       "\n",
       "                                Period of time (months)  \\\n",
       "Disease                                                   \n",
       "2002 SARS China                                     8.0   \n",
       "2008 HFMD China                                    52.0   \n",
       "2009 Meningitis West Africa                         3.0   \n",
       "2009 Influenza Mexico                              12.0   \n",
       "2012 MERS Saudi Arabia                             36.0   \n",
       "2015 Influenza India                                4.0   \n",
       "2019 Measles Samoa                                  4.0   \n",
       "2019 Measles Tonga                                  3.0   \n",
       "2019 Measles Rep. Of the Congo                     14.0   \n",
       "2019 Novel Coronavirus                              2.0   \n",
       "2018 HFMD Malaysia                                  8.0   \n",
       "\n",
       "                                Population density inhab/km3  Population  \\\n",
       "Disease                                                                    \n",
       "2002 SARS China                                       1128.0   8392000.0   \n",
       "2008 HFMD China                                          NaN    728000.0   \n",
       "2009 Meningitis West Africa                              NaN         NaN   \n",
       "2009 Influenza Mexico                                    NaN    800000.0   \n",
       "2012 MERS Saudi Arabia                                   NaN         NaN   \n",
       "2015 Influenza India                                     NaN         NaN   \n",
       "2019 Measles Samoa                                       NaN         NaN   \n",
       "2019 Measles Tonga                                       NaN         NaN   \n",
       "2019 Measles Rep. Of the Congo                           NaN         NaN   \n",
       "2019 Novel Coronavirus                                   NaN         NaN   \n",
       "2018 HFMD Malaysia                                       NaN         NaN   \n",
       "\n",
       "                                GDP (trillion USD) Infected rate  \\\n",
       "Disease                                                            \n",
       "2002 SARS China                             1471.0          0.10   \n",
       "2008 HFMD China                                NaN        208,83   \n",
       "2009 Meningitis West Africa                    NaN       #DIV/0!   \n",
       "2009 Influenza Mexico                          NaN      25000,00   \n",
       "2012 MERS Saudi Arabia                         NaN       #DIV/0!   \n",
       "2015 Influenza India                           NaN       #DIV/0!   \n",
       "2019 Measles Samoa                             NaN       #DIV/0!   \n",
       "2019 Measles Tonga                             NaN       #DIV/0!   \n",
       "2019 Measles Rep. Of the Congo                 NaN       #DIV/0!   \n",
       "2019 Novel Coronavirus                         NaN       #DIV/0!   \n",
       "2018 HFMD Malaysia                             NaN       #DIV/0!   \n",
       "\n",
       "                                Mortality rate  Temperature C (1st month)  \\\n",
       "Disease                                                                     \n",
       "2002 SARS China                           9.57                       19.4   \n",
       "2008 HFMD China                           0.03                        9.2   \n",
       "2009 Meningitis West Africa               4.40                        NaN   \n",
       "2009 Influenza Mexico                     0.20                        NaN   \n",
       "2012 MERS Saudi Arabia                   39.98                        NaN   \n",
       "2015 Influenza India                      6.03                        NaN   \n",
       "2019 Measles Samoa                        1.45                        NaN   \n",
       "2019 Measles Tonga                        0.00                        NaN   \n",
       "2019 Measles Rep. Of the Congo            2.40                        NaN   \n",
       "2019 Novel Coronavirus                    2.07                        NaN   \n",
       "2018 HFMD Malaysia                        0.00                        NaN   \n",
       "\n",
       "                                Humidity %(1st month)  Epidemic or not  \n",
       "Disease                                                                 \n",
       "2002 SARS China                                  64.0              1.0  \n",
       "2008 HFMD China                                  79.3              1.0  \n",
       "2009 Meningitis West Africa                       NaN              1.0  \n",
       "2009 Influenza Mexico                             NaN              1.0  \n",
       "2012 MERS Saudi Arabia                            NaN              1.0  \n",
       "2015 Influenza India                              NaN              1.0  \n",
       "2019 Measles Samoa                                NaN              1.0  \n",
       "2019 Measles Tonga                                NaN              1.0  \n",
       "2019 Measles Rep. Of the Congo                    NaN              1.0  \n",
       "2019 Novel Coronavirus                            NaN              1.0  \n",
       "2018 HFMD Malaysia                                NaN              0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_cols = 10\n",
    "raw_data = pd.read_csv('/Users/wilsonwu/OUTBRAIK/dataset_1.csv', sep=';', decimal=',', index_col='Disease')\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Death cases</th>\n",
       "      <th>Infected cases</th>\n",
       "      <th>Period of time (months)</th>\n",
       "      <th>Population density inhab/km3</th>\n",
       "      <th>Population</th>\n",
       "      <th>GDP (trillion USD)</th>\n",
       "      <th>Infected rate</th>\n",
       "      <th>Mortality rate</th>\n",
       "      <th>Temperature C (1st month)</th>\n",
       "      <th>Humidity %(1st month)</th>\n",
       "      <th>Epidemic or not</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disease</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2002 SARS China</td>\n",
       "      <td>774.0</td>\n",
       "      <td>8090.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1128.0</td>\n",
       "      <td>8392000.0</td>\n",
       "      <td>1471.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>9.57</td>\n",
       "      <td>19.4</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Death cases  Infected cases  Period of time (months)  \\\n",
       "Disease                                                                 \n",
       "2002 SARS China        774.0          8090.0                      8.0   \n",
       "\n",
       "                 Population density inhab/km3  Population  GDP (trillion USD)  \\\n",
       "Disease                                                                         \n",
       "2002 SARS China                        1128.0   8392000.0              1471.0   \n",
       "\n",
       "                Infected rate  Mortality rate  Temperature C (1st month)  \\\n",
       "Disease                                                                    \n",
       "2002 SARS China          0.10            9.57                       19.4   \n",
       "\n",
       "                 Humidity %(1st month)  Epidemic or not  \n",
       "Disease                                                  \n",
       "2002 SARS China                   64.0              1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop Region column and only use first row.\n",
    "train_set = raw_data.drop('Region', axis=1).iloc[[0],:]\n",
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'>\n",
      "774.0\n",
      "<class 'numpy.float64'>\n",
      "8090.0\n",
      "<class 'numpy.float64'>\n",
      "8.0\n",
      "<class 'numpy.float64'>\n",
      "1128.0\n",
      "<class 'numpy.float64'>\n",
      "8392000.0\n",
      "<class 'numpy.float64'>\n",
      "1471.0\n",
      "<class 'str'>\n",
      "0.10\n",
      "<class 'numpy.float64'>\n",
      "9.57\n",
      "<class 'numpy.float64'>\n",
      "19.4\n",
      "<class 'numpy.float64'>\n",
      "64.0\n",
      "<class 'numpy.float64'>\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for x in train_set.iloc[0,:].values.tolist():\n",
    "    print(type(x))\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Death cases</th>\n",
       "      <th>Infected cases</th>\n",
       "      <th>Period of time (months)</th>\n",
       "      <th>Population density inhab/km3</th>\n",
       "      <th>Population</th>\n",
       "      <th>GDP (trillion USD)</th>\n",
       "      <th>Infected rate</th>\n",
       "      <th>Mortality rate</th>\n",
       "      <th>Temperature C (1st month)</th>\n",
       "      <th>Humidity %(1st month)</th>\n",
       "      <th>Epidemic or not</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disease</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2002 SARS China</td>\n",
       "      <td>774.0</td>\n",
       "      <td>8090.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1128.0</td>\n",
       "      <td>8392000.0</td>\n",
       "      <td>1471.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>9.57</td>\n",
       "      <td>19.4</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Death cases  Infected cases  Period of time (months)  \\\n",
       "Disease                                                                 \n",
       "2002 SARS China        774.0          8090.0                      8.0   \n",
       "\n",
       "                 Population density inhab/km3  Population  GDP (trillion USD)  \\\n",
       "Disease                                                                         \n",
       "2002 SARS China                        1128.0   8392000.0              1471.0   \n",
       "\n",
       "                Infected rate  Mortality rate  Temperature C (1st month)  \\\n",
       "Disease                                                                    \n",
       "2002 SARS China          0.10            9.57                       19.4   \n",
       "\n",
       "                 Humidity %(1st month)  Epidemic or not  \n",
       "Disease                                                  \n",
       "2002 SARS China                   64.0              1.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.applymap(lambda x: str(x).replace(\",\", \".\") if isinstance(x, float) else x)\n",
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_df = train_set.apply(pd.to_numeric).astype(float).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[784.0, 8100.0, 18.0, 1138.0, 8392010.0, 1481.0, 10.1, 19.57, 29.4, 74.0, 11.0]\n",
      "[784.0, 8100.0, 18.0, 1138.0, 8392010.0, 1481.0, 10.1, 19.57, 29.4, 74.0, 11.0]\n",
      "[784.0, 8100.0, 18.0, 1138.0, 8392010.0, 1481.0, 10.1, 19.57, 29.4, 74.0, 11.0]\n",
      "[784.0, 8100.0, 18.0, 1138.0, 8392010.0, 1481.0, 10.1, 19.57, 29.4, 74.0, 11.0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Death cases</th>\n",
       "      <th>Infected cases</th>\n",
       "      <th>Period of time (months)</th>\n",
       "      <th>Population density inhab/km3</th>\n",
       "      <th>Population</th>\n",
       "      <th>GDP (trillion USD)</th>\n",
       "      <th>Infected rate</th>\n",
       "      <th>Mortality rate</th>\n",
       "      <th>Temperature C (1st month)</th>\n",
       "      <th>Humidity %(1st month)</th>\n",
       "      <th>Epidemic or not</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2002 SARS China</td>\n",
       "      <td>774.0</td>\n",
       "      <td>8090.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1128.0</td>\n",
       "      <td>8392000.0</td>\n",
       "      <td>1471.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>9.57</td>\n",
       "      <td>19.4</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>784.0</td>\n",
       "      <td>8100.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8392010.0</td>\n",
       "      <td>1481.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>19.57</td>\n",
       "      <td>29.4</td>\n",
       "      <td>74.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>784.0</td>\n",
       "      <td>8100.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8392010.0</td>\n",
       "      <td>1481.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>19.57</td>\n",
       "      <td>29.4</td>\n",
       "      <td>74.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>784.0</td>\n",
       "      <td>8100.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8392010.0</td>\n",
       "      <td>1481.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>19.57</td>\n",
       "      <td>29.4</td>\n",
       "      <td>74.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>784.0</td>\n",
       "      <td>8100.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8392010.0</td>\n",
       "      <td>1481.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>19.57</td>\n",
       "      <td>29.4</td>\n",
       "      <td>74.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Death cases  Infected cases  Period of time (months)  \\\n",
       "2002 SARS China        774.0          8090.0                      8.0   \n",
       "0                      784.0          8100.0                     18.0   \n",
       "0                      784.0          8100.0                     18.0   \n",
       "0                      784.0          8100.0                     18.0   \n",
       "0                      784.0          8100.0                     18.0   \n",
       "\n",
       "                 Population density inhab/km3  Population  GDP (trillion USD)  \\\n",
       "2002 SARS China                        1128.0   8392000.0              1471.0   \n",
       "0                                      1138.0   8392010.0              1481.0   \n",
       "0                                      1138.0   8392010.0              1481.0   \n",
       "0                                      1138.0   8392010.0              1481.0   \n",
       "0                                      1138.0   8392010.0              1481.0   \n",
       "\n",
       "                 Infected rate  Mortality rate  Temperature C (1st month)  \\\n",
       "2002 SARS China            0.1            9.57                       19.4   \n",
       "0                         10.1           19.57                       29.4   \n",
       "0                         10.1           19.57                       29.4   \n",
       "0                         10.1           19.57                       29.4   \n",
       "0                         10.1           19.57                       29.4   \n",
       "\n",
       "                 Humidity %(1st month)  Epidemic or not  \n",
       "2002 SARS China                   64.0              1.0  \n",
       "0                                 74.0             11.0  \n",
       "0                                 74.0             11.0  \n",
       "0                                 74.0             11.0  \n",
       "0                                 74.0             11.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10\n",
    "for i in range(4):\n",
    "    new_row = [x + n for x in float_df.iloc[0,:].values.tolist()]\n",
    "    print(new_row)\n",
    "    float_df = float_df.append(pd.DataFrame([new_row], columns=train_set.columns), sort=False)\n",
    "float_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Death cases</th>\n",
       "      <th>Infected cases</th>\n",
       "      <th>Period of time (months)</th>\n",
       "      <th>Population density inhab/km3</th>\n",
       "      <th>Population</th>\n",
       "      <th>GDP (trillion USD)</th>\n",
       "      <th>Infected rate</th>\n",
       "      <th>Mortality rate</th>\n",
       "      <th>Temperature C (1st month)</th>\n",
       "      <th>Humidity %(1st month)</th>\n",
       "      <th>Epidemic or not</th>\n",
       "      <th>Epidemic or no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2002 SARS China</td>\n",
       "      <td>774.0</td>\n",
       "      <td>8090.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1128.0</td>\n",
       "      <td>8392000.0</td>\n",
       "      <td>1471.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>9.57</td>\n",
       "      <td>19.4</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>784.0</td>\n",
       "      <td>8100.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8392010.0</td>\n",
       "      <td>1481.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>19.57</td>\n",
       "      <td>29.4</td>\n",
       "      <td>74.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>784.0</td>\n",
       "      <td>8100.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8392010.0</td>\n",
       "      <td>1481.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>19.57</td>\n",
       "      <td>29.4</td>\n",
       "      <td>74.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>784.0</td>\n",
       "      <td>8100.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8392010.0</td>\n",
       "      <td>1481.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>19.57</td>\n",
       "      <td>29.4</td>\n",
       "      <td>74.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>784.0</td>\n",
       "      <td>8100.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8392010.0</td>\n",
       "      <td>1481.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>19.57</td>\n",
       "      <td>29.4</td>\n",
       "      <td>74.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Death cases  Infected cases  Period of time (months)  \\\n",
       "2002 SARS China        774.0          8090.0                      8.0   \n",
       "0                      784.0          8100.0                     18.0   \n",
       "0                      784.0          8100.0                     18.0   \n",
       "0                      784.0          8100.0                     18.0   \n",
       "0                      784.0          8100.0                     18.0   \n",
       "\n",
       "                 Population density inhab/km3  Population  GDP (trillion USD)  \\\n",
       "2002 SARS China                        1128.0   8392000.0              1471.0   \n",
       "0                                      1138.0   8392010.0              1481.0   \n",
       "0                                      1138.0   8392010.0              1481.0   \n",
       "0                                      1138.0   8392010.0              1481.0   \n",
       "0                                      1138.0   8392010.0              1481.0   \n",
       "\n",
       "                 Infected rate  Mortality rate  Temperature C (1st month)  \\\n",
       "2002 SARS China            0.1            9.57                       19.4   \n",
       "0                         10.1           19.57                       29.4   \n",
       "0                         10.1           19.57                       29.4   \n",
       "0                         10.1           19.57                       29.4   \n",
       "0                         10.1           19.57                       29.4   \n",
       "\n",
       "                 Humidity %(1st month)  Epidemic or not  Epidemic or no  \n",
       "2002 SARS China                   64.0              1.0             1.0  \n",
       "0                                 74.0             11.0             1.0  \n",
       "0                                 74.0             11.0             0.0  \n",
       "0                                 74.0             11.0             1.0  \n",
       "0                                 74.0             11.0             0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_df['Epidemic or no'] = [1.0, 1.0, 0.0, 1.0, 0.0]\n",
    "float_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "node"
    ]
   },
   "outputs": [],
   "source": [
    "def split_dataset(dataframe, n_splits):\n",
    "    \"\"\"Scikit-Learn KFold implementation for pandas DataFrame.\"\"\"\n",
    "\n",
    "    label_col = 'Epidemic or no'\n",
    "    random_state = 2\n",
    "    \n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    kfolds = []\n",
    "    global offset_col_name\n",
    "\n",
    "    for train, validate in kf.split(dataframe):\n",
    "        training = dataframe.iloc[train]\n",
    "        train_labels = training[label_col]\n",
    "        train_set = training.drop(label_col, axis=1)\n",
    "\n",
    "        validating = dataframe.iloc[validate]\n",
    "        validate_labels = validating[label_col]\n",
    "        validate_set = validating.drop(label_col, axis=1)\n",
    "\n",
    "        kfolds.append(\n",
    "            [[train_set, validate_set],\n",
    "             [train_labels, validate_labels]]\n",
    "        )\n",
    "\n",
    "    with open('/Users/wilsonwu/OUTBRAIK/outbraik/data/06_models/kfolds.json', \"wb\") as file:\n",
    "        pickle.dump(kfolds, file)\n",
    "\n",
    "    logging.info('Pickled kfolds nested list to JSON.')\n",
    "    return kfolds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tensorflow DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "node"
    ]
   },
   "outputs": [],
   "source": [
    "def create_model(num_dense_layers_base, num_dense_nodes_base,\n",
    "                 num_dense_layers_end, num_dense_nodes_end,\n",
    "                 activation, adam_b1, adam_b2, adam_eps):\n",
    "    \n",
    "    num_input_nodes = 11\n",
    "    \n",
    "    # Craete linear stack of layers.\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # Define input layer.\n",
    "    model.add(keras.layers.Dense(\n",
    "        num_input_nodes,  # N.umber of nodes\n",
    "        input_shape=(num_input_nodes,)  # Tuple specifying data input dimensions only needed in first layer.\n",
    "             ))\n",
    "\n",
    "    # Define n number of hidden layers (base, i.e. first layers).\n",
    "    for i in range(num_dense_layers_base):\n",
    "        model.add(keras.layers.Dense(\n",
    "            num_dense_nodes_base,\n",
    "            activation=activation\n",
    "        ))\n",
    "\n",
    "    # Define n number of hidden layers (end, i.e. last layers).\n",
    "    for i in range(num_dense_layers_end):\n",
    "        model.add(keras.layers.Dense(\n",
    "            num_dense_nodes_end,\n",
    "            activation=activation\n",
    "        ))\n",
    "\n",
    "    # Add two output nodes.\n",
    "    model.add(keras.layers.Dense(2, activation=keras.activations.linear))\n",
    "\n",
    "    # Define dam optimiser.\n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "        lr=0.0001,  # Learning rate\n",
    "        beta_1=adam_b1,  # Exponential decay rate for the first moment estimates.\n",
    "        beta_2=adam_b2,  # Exponential decay rate for the second-moment estimates.\n",
    "        epsilon=adam_eps  # Prevent any division by zero.\n",
    "    )\n",
    "\n",
    "    # Compile model.\n",
    "    model.compile(\n",
    "        loss='mae',  # Loss function\n",
    "        optimizer=optimizer,  # Optimisaion function defined above.\n",
    "        metrics=['mae']  # Metric to be recorded.\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "node"
    ]
   },
   "outputs": [],
   "source": [
    "def train_model(fold, fold_num, n_calls, epochs):\n",
    "    \"\"\"\n",
    "    1. Unpack training data.\n",
    "    2. Define hyper-perameter ranges.\n",
    "    3. Define early stopping perameters.\n",
    "    4. Optimise hyper-perameters and save best model.\n",
    "    5. Save mae per call to CSV.\n",
    "    \"\"\"\n",
    "    logging.info('Training fold {}.'.format(str(fold_num)))\n",
    "    \n",
    "    # Retrieve data sets and convert to numpy array.\n",
    "    train_X = fold[0][0].values\n",
    "    validate_X = fold[0][1].values\n",
    "    train_y = fold[1][0].values\n",
    "    validate_y = fold[1][1].values\n",
    "\n",
    "    # Define hyper-perameters.\n",
    "    # Layers\n",
    "    dim_num_dense_layers_base = Integer(low=1, high=2, name='num_dense_layers_base')\n",
    "    dim_num_dense_nodes_base = Categorical(categories=list(np.linspace(5, 261, 10, dtype=int)),\n",
    "                                           name='num_dense_nodes_base')\n",
    "    dim_num_dense_layers_end = Integer(low=1, high=2, name='num_dense_layers_end')\n",
    "    dim_num_dense_nodes_end = Categorical(categories=list(np.linspace(5, 261, 10, dtype=int)),\n",
    "                                          name='num_dense_nodes_end')\n",
    "\n",
    "    # Optimiser\n",
    "    dim_adam_b1 = Categorical(categories=list(np.linspace(0.8, 0.99, 11)), name='adam_b1')\n",
    "    dim_adam_b2 = Categorical(categories=list(np.linspace(0.8, 0.99, 11)), name='adam_b2')\n",
    "    dim_adam_eps = Categorical(categories=list(np.linspace(0.0001, 0.5, 11)), name='adam_eps')\n",
    "\n",
    "    dimensions = [dim_num_dense_layers_base, dim_num_dense_nodes_base,\n",
    "                  dim_num_dense_layers_end, dim_num_dense_nodes_end,\n",
    "                  dim_adam_b1, dim_adam_b2, dim_adam_eps]\n",
    "\n",
    "    # Set early stopping variable to prevent overfitting.\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',  # Monitor validation loss\n",
    "        mode='min',  # Monitoring loss\n",
    "        patience=20,  # Large patience for small batch size\n",
    "        verbose=0)  # Do not output to terminal\n",
    "\n",
    "    best_mae = np.inf\n",
    "    \n",
    "    # Start hyper-perameter optimisation.\n",
    "    @use_named_args(dimensions=dimensions)\n",
    "    def fitness(num_dense_layers_base, num_dense_nodes_base,\n",
    "                num_dense_layers_end, num_dense_nodes_end,\n",
    "                adam_b1, adam_b2, adam_eps):\n",
    "\n",
    "        # Create the neural network with these hyper-parameters.\n",
    "        model = create_model(num_dense_layers_base=num_dense_layers_base,\n",
    "                             num_dense_nodes_base=num_dense_nodes_base,\n",
    "                             num_dense_layers_end=num_dense_layers_end,\n",
    "                             num_dense_nodes_end=num_dense_nodes_end,\n",
    "                             activation=tf.keras.activations.relu,\n",
    "                             adam_b1=adam_b1, adam_b2=adam_b2, adam_eps=adam_eps)\n",
    "\n",
    "        history = model.fit(train_X, train_y, # Training data\n",
    "                            epochs=epochs,  # Number of forward and backward runs.\n",
    "                            validation_data=(validate_X, validate_y),  # Validation data\n",
    "                            verbose=1,\n",
    "                            callbacks=[early_stopping],  # Prevent overfitting.\n",
    "                            batch_size=30)  # Increase efficiency\n",
    "\n",
    "        mae = history.history['val_mae'][-1]\n",
    "        # If the regressor accuracy of the saved model is improved...\n",
    "        nonlocal  best_mae\n",
    "        if mae < best_mae:\n",
    "            # Save the new model to harddisk.\n",
    "            model.save('/Users/wilsonwu/OUTBRAIK/outbraik/data/06_models/fold_' + str(fold_num) + '_model.h5')\n",
    "            # Update the regressor accuracy.\n",
    "            best_mae = mae\n",
    "\n",
    "        # Delete the Keras model with these hyper-parameters from memory.\n",
    "        del model\n",
    "\n",
    "        # Clear the Keras session, otherwise it will keep adding new\n",
    "        # models to the same TensorFlow graph each time we create\n",
    "        # a model with a different set of hyper-parameters.\n",
    "        K.clear_session()\n",
    "\n",
    "        # Reset best MAE.\n",
    "        best_mae = np.inf\n",
    "\n",
    "        return mae\n",
    "\n",
    "    # A place for optimiser to start looking.\n",
    "    default_parameters = [2, 261, 1, 61, 0.857, 0.933, 0.20006]\n",
    "\n",
    "    search_result = gp_minimize(func=fitness,\n",
    "                                dimensions=dimensions,\n",
    "                                acq_func='EI',  # Expected Improvement\n",
    "                                n_calls=n_calls,\n",
    "                                x0=default_parameters)\n",
    "\n",
    "    # Save skopt object.\n",
    "    dump(search_result,\n",
    "         '/Users/wilsonwu/OUTBRAIK/outbraik/data/06_models/fold_' + str(fold_num) +  '_gp_minimize_result.pickle',\n",
    "         store_objective=False)\n",
    "    logging.info('Pickled fold {} Scikit-Optimise object.'.format(fold_num))\n",
    "\n",
    "    logging.info('Fold {} final parameters: {}.'.format(str(fold_num), search_result.x))\n",
    "    return search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "node"
    ]
   },
   "outputs": [],
   "source": [
    "def train_DNN(dataframe, n_splits, n_calls, epochs):\n",
    "    \n",
    "    kfolds = split_dataset(dataframe, n_splits)\n",
    "    all_models = [train_model(fold, fold_num+1, n_calls, epochs) for fold_num, fold in enumerate(kfolds)]\n",
    "\n",
    "    return all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 2s 434ms/sample - loss: 478758.9375 - mae: 478758.9375 - val_loss: 414703.5312 - val_mae: 414703.5312\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 23ms/sample - loss: 414703.6562 - mae: 414703.6562 - val_loss: 350759.6875 - val_mae: 350759.6875\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 26ms/sample - loss: 350759.8750 - mae: 350759.8750 - val_loss: 287419.4688 - val_mae: 287419.4688\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 1s 371ms/sample - loss: 815088.6875 - mae: 815088.6875 - val_loss: 734241.1875 - val_mae: 734241.1875\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 22ms/sample - loss: 734240.7500 - mae: 734240.7500 - val_loss: 654581.7500 - val_mae: 654581.7500\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 26ms/sample - loss: 654581.5000 - mae: 654581.5000 - val_loss: 602684.5625 - val_mae: 602684.5625\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 2s 398ms/sample - loss: 406635.7500 - mae: 406635.7500 - val_loss: 360322.7188 - val_mae: 360322.7188\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 19ms/sample - loss: 360322.4375 - mae: 360322.4375 - val_loss: 314353.5000 - val_mae: 314353.5000\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 25ms/sample - loss: 314353.1875 - mae: 314353.1875 - val_loss: 268775.5000 - val_mae: 268775.5000\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 1s 341ms/sample - loss: 148484.8438 - mae: 148484.8438 - val_loss: 143644.1406 - val_mae: 143644.1406\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 18ms/sample - loss: 143644.1406 - mae: 143644.1406 - val_loss: 138833.7188 - val_mae: 138833.7188\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 18ms/sample - loss: 138833.6562 - mae: 138833.6562 - val_loss: 134053.5469 - val_mae: 134053.5469\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 1s 321ms/sample - loss: 1019420.1875 - mae: 1019420.1875 - val_loss: 979412.8750 - val_mae: 979412.8750\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 24ms/sample - loss: 979412.5000 - mae: 979412.5000 - val_loss: 939934.1875 - val_mae: 939934.1875\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 33ms/sample - loss: 939933.5000 - mae: 939933.5000 - val_loss: 900572.7500 - val_mae: 900572.7500\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 1s 370ms/sample - loss: 45848.6094 - mae: 45848.6094 - val_loss: 31006.7148 - val_mae: 31006.7148\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 19ms/sample - loss: 31006.5625 - mae: 31006.5625 - val_loss: 16164.2412 - val_mae: 16164.2412\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 23ms/sample - loss: 16164.0811 - mae: 16164.0811 - val_loss: 11357.3564 - val_mae: 11357.3564\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 1s 362ms/sample - loss: 374346.0000 - mae: 374346.0000 - val_loss: 357131.9688 - val_mae: 357131.9688\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 18ms/sample - loss: 357132.0625 - mae: 357132.0625 - val_loss: 340291.6875 - val_mae: 340291.6875\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 19ms/sample - loss: 340291.7500 - mae: 340291.7500 - val_loss: 323707.4375 - val_mae: 323707.4375\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 1s 367ms/sample - loss: 511107.1875 - mae: 511107.1875 - val_loss: 442362.1562 - val_mae: 442362.1562\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 59ms/sample - loss: 442361.8750 - mae: 442361.8750 - val_loss: 376175.5625 - val_mae: 376175.5625\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 66ms/sample - loss: 376175.2500 - mae: 376175.2500 - val_loss: 312221.3438 - val_mae: 312221.3438\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 3s 738ms/sample - loss: 907792.1250 - mae: 907792.1250 - val_loss: 884939.0000 - val_mae: 884939.0000\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 37ms/sample - loss: 884939.3750 - mae: 884939.3750 - val_loss: 862113.1250 - val_mae: 862113.1250\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 27ms/sample - loss: 862113.2500 - mae: 862113.2500 - val_loss: 839314.0000 - val_mae: 839314.0000\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 1s 344ms/sample - loss: 853370.7500 - mae: 853370.7500 - val_loss: 846381.3125 - val_mae: 846381.3125\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 19ms/sample - loss: 846382.2500 - mae: 846382.2500 - val_loss: 839401.3750 - val_mae: 839401.3750\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 18ms/sample - loss: 839402.2500 - mae: 839402.2500 - val_loss: 832430.0625 - val_mae: 832430.0625\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 1s 317ms/sample - loss: 87940.5859 - mae: 87940.5859 - val_loss: 66557.5625 - val_mae: 66557.5625\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 24ms/sample - loss: 66558.6094 - mae: 66558.6094 - val_loss: 29995.6992 - val_mae: 29995.6992\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 25ms/sample - loss: 29996.7871 - mae: 29996.7871 - val_loss: 15139.2822 - val_mae: 15139.2822\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 1s 344ms/sample - loss: 383601.0625 - mae: 383601.0625 - val_loss: 310561.2500 - val_mae: 310561.2500\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 23ms/sample - loss: 310561.8125 - mae: 310561.8125 - val_loss: 238018.3750 - val_mae: 238018.3750\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 25ms/sample - loss: 238019.0625 - mae: 238019.0625 - val_loss: 166154.9688 - val_mae: 166154.9688\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 1s 364ms/sample - loss: 755610.5000 - mae: 755610.5000 - val_loss: 724969.2500 - val_mae: 724969.2500\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 18ms/sample - loss: 724969.1250 - mae: 724969.1250 - val_loss: 694057.1875 - val_mae: 694057.1875\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 19ms/sample - loss: 694056.9375 - mae: 694056.9375 - val_loss: 663217.0000 - val_mae: 663217.0000\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 1s 340ms/sample - loss: 596407.5000 - mae: 596407.5000 - val_loss: 585964.3750 - val_mae: 585964.3750\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 20ms/sample - loss: 585964.3125 - mae: 585964.3125 - val_loss: 575543.0000 - val_mae: 575543.0000\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 39ms/sample - loss: 575543.2500 - mae: 575543.2500 - val_loss: 565143.3750 - val_mae: 565143.3750\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 1s 369ms/sample - loss: 802442.1250 - mae: 802442.1250 - val_loss: 770556.6250 - val_mae: 770556.6250\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 20ms/sample - loss: 770556.1250 - mae: 770556.1250 - val_loss: 739429.0000 - val_mae: 739429.0000\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 26ms/sample - loss: 739428.3125 - mae: 739428.3125 - val_loss: 708482.2500 - val_mae: 708482.2500\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 2s 593ms/sample - loss: 294547.7500 - mae: 294547.7500 - val_loss: 251694.6875 - val_mae: 251694.6875\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 21ms/sample - loss: 251694.9531 - mae: 251694.9531 - val_loss: 208993.0312 - val_mae: 208993.0312\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 26ms/sample - loss: 208993.4375 - mae: 208993.4375 - val_loss: 166044.9688 - val_mae: 166044.9688\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 2s 494ms/sample - loss: 125719.6250 - mae: 125719.6250 - val_loss: 117437.5391 - val_mae: 117437.5391\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 25ms/sample - loss: 117437.4531 - mae: 117437.4531 - val_loss: 95306.5078 - val_mae: 95306.5078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 28ms/sample - loss: 95306.4297 - mae: 95306.4297 - val_loss: 65721.7812 - val_mae: 65721.7812\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 2s 389ms/sample - loss: 328067.7812 - mae: 328067.7812 - val_loss: 307937.6562 - val_mae: 307937.6562\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 18ms/sample - loss: 307938.6250 - mae: 307938.6250 - val_loss: 287853.9375 - val_mae: 287853.9375\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 19ms/sample - loss: 287854.8438 - mae: 287854.8438 - val_loss: 267815.0625 - val_mae: 267815.0625\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 1s 340ms/sample - loss: 308793.1875 - mae: 308793.1875 - val_loss: 271953.9375 - val_mae: 271953.9375\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 18ms/sample - loss: 271954.7500 - mae: 271954.7500 - val_loss: 235388.5000 - val_mae: 235388.5000\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 22ms/sample - loss: 235389.3281 - mae: 235389.3281 - val_loss: 198887.4219 - val_mae: 198887.4219\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 2s 375ms/sample - loss: 306757.3750 - mae: 306757.3750 - val_loss: 301118.0000 - val_mae: 301118.0000\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 18ms/sample - loss: 301118.3750 - mae: 301118.3750 - val_loss: 295491.0000 - val_mae: 295491.0000\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 18ms/sample - loss: 295491.2500 - mae: 295491.2500 - val_loss: 289875.6875 - val_mae: 289875.6875\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 2s 393ms/sample - loss: 342349.5625 - mae: 342349.5625 - val_loss: 335875.0312 - val_mae: 335875.0312\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 26ms/sample - loss: 335875.0000 - mae: 335875.0000 - val_loss: 304320.1562 - val_mae: 304320.1562\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 25ms/sample - loss: 304320.0312 - mae: 304320.0312 - val_loss: 265281.2812 - val_mae: 265281.2812\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 1s 344ms/sample - loss: 197206.8750 - mae: 197206.8750 - val_loss: 171072.1094 - val_mae: 171072.1094\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 23ms/sample - loss: 171071.7500 - mae: 171071.7500 - val_loss: 144946.2344 - val_mae: 144946.2344\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 24ms/sample - loss: 144945.9375 - mae: 144945.9375 - val_loss: 137310.6406 - val_mae: 137310.6406\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 2s 500ms/sample - loss: 248927.2188 - mae: 248927.2188 - val_loss: 185220.3906 - val_mae: 185220.3906\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 33ms/sample - loss: 185220.4688 - mae: 185220.4688 - val_loss: 161223.2500 - val_mae: 161223.2500\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 36ms/sample - loss: 161224.0625 - mae: 161224.0625 - val_loss: 128601.5781 - val_mae: 128601.5781\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 2s 472ms/sample - loss: 538872.3750 - mae: 538872.3750 - val_loss: 497914.3750 - val_mae: 497914.3750\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 21ms/sample - loss: 497914.4688 - mae: 497914.4688 - val_loss: 457024.4375 - val_mae: 457024.4375\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 18ms/sample - loss: 457024.5000 - mae: 457024.5000 - val_loss: 416323.6875 - val_mae: 416323.6875\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 2s 477ms/sample - loss: 109132.7656 - mae: 109132.7656 - val_loss: 88976.8516 - val_mae: 88976.8516\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 25ms/sample - loss: 88977.0625 - mae: 88977.0625 - val_loss: 69477.9922 - val_mae: 69477.9922\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 24ms/sample - loss: 69478.2344 - mae: 69478.2344 - val_loss: 58584.3828 - val_mae: 58584.3828\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 2s 492ms/sample - loss: 260152.7031 - mae: 260152.7031 - val_loss: 217057.4375 - val_mae: 217057.4375\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 32ms/sample - loss: 217057.0312 - mae: 217057.0312 - val_loss: 185548.5000 - val_mae: 185548.5000\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 35ms/sample - loss: 185548.0000 - mae: 185548.0000 - val_loss: 151832.0781 - val_mae: 151832.0781\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 2s 606ms/sample - loss: 630128.5625 - mae: 630128.5625 - val_loss: 604912.0000 - val_mae: 604912.0000\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 36ms/sample - loss: 604912.3750 - mae: 604912.3750 - val_loss: 579854.7500 - val_mae: 579854.7500\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 26ms/sample - loss: 579855.1250 - mae: 579855.1250 - val_loss: 554901.8750 - val_mae: 554901.8750\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 3s 714ms/sample - loss: 258722.1250 - mae: 258722.1250 - val_loss: 238896.0938 - val_mae: 238896.0938\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 31ms/sample - loss: 238895.9375 - mae: 238895.9375 - val_loss: 217778.1406 - val_mae: 217778.1406\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 32ms/sample - loss: 217777.8438 - mae: 217777.8438 - val_loss: 199714.2188 - val_mae: 199714.2188\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 2s 497ms/sample - loss: 165235.1562 - mae: 165235.1562 - val_loss: 138151.2188 - val_mae: 138151.2188\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 33ms/sample - loss: 138151.5625 - mae: 138151.5625 - val_loss: 107909.4062 - val_mae: 107909.4062\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 33ms/sample - loss: 107909.7812 - mae: 107909.7812 - val_loss: 73478.6719 - val_mae: 73478.6719\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 2s 511ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 24ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 24ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 2s 491ms/sample - loss: 225038.0000 - mae: 225038.0000 - val_loss: 189251.0156 - val_mae: 189251.0156\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 31ms/sample - loss: 189251.3438 - mae: 189251.3438 - val_loss: 153768.5000 - val_mae: 153768.5000\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 48ms/sample - loss: 153768.7188 - mae: 153768.7188 - val_loss: 117775.4766 - val_mae: 117775.4766\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 3s 733ms/sample - loss: 250284.7031 - mae: 250284.7031 - val_loss: 208903.5312 - val_mae: 208903.5312\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 36ms/sample - loss: 208903.5625 - mae: 208903.5625 - val_loss: 182007.7500 - val_mae: 182007.7500\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 52ms/sample - loss: 182007.7500 - mae: 182007.7500 - val_loss: 148929.0625 - val_mae: 148929.0625\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 2s 548ms/sample - loss: 482014.8125 - mae: 482014.8125 - val_loss: 405806.1875 - val_mae: 405806.1875\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 33ms/sample - loss: 405805.5625 - mae: 405805.5625 - val_loss: 330610.6250 - val_mae: 330610.6250\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 35ms/sample - loss: 330610.0000 - mae: 330610.0000 - val_loss: 256029.8125 - val_mae: 256029.8125\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 2s 498ms/sample - loss: 362399.2500 - mae: 362399.2500 - val_loss: 274475.2812 - val_mae: 274475.2812\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 30ms/sample - loss: 274474.5625 - mae: 274474.5625 - val_loss: 194269.3125 - val_mae: 194269.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 34ms/sample - loss: 194268.6719 - mae: 194268.6719 - val_loss: 120502.8125 - val_mae: 120502.8125\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 2s 493ms/sample - loss: 56664.8203 - mae: 56664.8203 - val_loss: 16509.8594 - val_mae: 16509.8594\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 36ms/sample - loss: 16509.4570 - mae: 16509.4570 - val_loss: 34562.5312 - val_mae: 34562.5312\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 35ms/sample - loss: 34563.2578 - mae: 34563.2578 - val_loss: 42899.3711 - val_mae: 42899.3711\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 2s 512ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 24ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 24ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 2s 543ms/sample - loss: 189412.7656 - mae: 189412.7656 - val_loss: 137882.0625 - val_mae: 137882.0625\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 32ms/sample - loss: 137881.9531 - mae: 137881.9531 - val_loss: 106280.0391 - val_mae: 106280.0391\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 34ms/sample - loss: 106279.9531 - mae: 106279.9531 - val_loss: 65727.2031 - val_mae: 65727.2031\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 2s 464ms/sample - loss: 812948.7500 - mae: 812948.7500 - val_loss: 768103.2500 - val_mae: 768103.2500\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 24ms/sample - loss: 768103.6250 - mae: 768103.6250 - val_loss: 723274.0000 - val_mae: 723274.0000\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 22ms/sample - loss: 723274.4375 - mae: 723274.4375 - val_loss: 678460.6250 - val_mae: 678460.6250\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 2s 462ms/sample - loss: 331384.2500 - mae: 331384.2500 - val_loss: 317332.4375 - val_mae: 317332.4375\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 22ms/sample - loss: 317331.2500 - mae: 317331.2500 - val_loss: 303349.3438 - val_mae: 303349.3438\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 22ms/sample - loss: 303348.2812 - mae: 303348.2812 - val_loss: 289424.1250 - val_mae: 289424.1250\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 2s 494ms/sample - loss: 461407.9375 - mae: 461407.9375 - val_loss: 459230.7500 - val_mae: 459230.7500\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 21ms/sample - loss: 459230.1875 - mae: 459230.1875 - val_loss: 457057.8438 - val_mae: 457057.8438\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 21ms/sample - loss: 457057.1875 - mae: 457057.1875 - val_loss: 454889.2812 - val_mae: 454889.2812\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 2s 443ms/sample - loss: 231063.9219 - mae: 231063.9219 - val_loss: 224087.7812 - val_mae: 224087.7812\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 28ms/sample - loss: 224088.0469 - mae: 224088.0469 - val_loss: 186357.1406 - val_mae: 186357.1406\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 28ms/sample - loss: 186357.5000 - mae: 186357.5000 - val_loss: 140548.1875 - val_mae: 140548.1875\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 2s 526ms/sample - loss: 25712.8496 - mae: 25712.8496 - val_loss: 16247.6191 - val_mae: 16247.6191\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 24ms/sample - loss: 16247.5684 - mae: 16247.5684 - val_loss: 6807.7119 - val_mae: 6807.7119\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 21ms/sample - loss: 6807.7065 - mae: 6807.7065 - val_loss: 3011.7812 - val_mae: 3011.7812\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 2s 423ms/sample - loss: 215417.9375 - mae: 215417.9375 - val_loss: 191178.7188 - val_mae: 191178.7188\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 22ms/sample - loss: 191178.5000 - mae: 191178.5000 - val_loss: 167003.4531 - val_mae: 167003.4531\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 28ms/sample - loss: 167003.0938 - mae: 167003.0938 - val_loss: 142898.5312 - val_mae: 142898.5312\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 1s 339ms/sample - loss: 603074.5625 - mae: 603074.5625 - val_loss: 557139.9375 - val_mae: 557139.9375\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 26ms/sample - loss: 557139.5625 - mae: 557139.5625 - val_loss: 511483.7500 - val_mae: 511483.7500\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 24ms/sample - loss: 511483.4062 - mae: 511483.4062 - val_loss: 465873.0000 - val_mae: 465873.0000\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 2s 424ms/sample - loss: 327496.5625 - mae: 327496.5625 - val_loss: 238550.0625 - val_mae: 238550.0625\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 26ms/sample - loss: 238551.2969 - mae: 238551.2969 - val_loss: 149961.2031 - val_mae: 149961.2031\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 31ms/sample - loss: 149962.4844 - mae: 149962.4844 - val_loss: 66019.2422 - val_mae: 66019.2422\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 2s 424ms/sample - loss: 276927.6250 - mae: 276927.6250 - val_loss: 221082.4844 - val_mae: 221082.4844\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 26ms/sample - loss: 221082.1875 - mae: 221082.1875 - val_loss: 167530.7031 - val_mae: 167530.7031\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 26ms/sample - loss: 167530.7344 - mae: 167530.7344 - val_loss: 115578.9531 - val_mae: 115578.9531\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 2s 439ms/sample - loss: 720769.8750 - mae: 720769.8750 - val_loss: 688013.5000 - val_mae: 688013.5000\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 22ms/sample - loss: 688012.0000 - mae: 688012.0000 - val_loss: 656161.3125 - val_mae: 656161.3125\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 21ms/sample - loss: 656159.5000 - mae: 656159.5000 - val_loss: 624404.6875 - val_mae: 624404.6875\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 1s 330ms/sample - loss: 771146.0000 - mae: 771146.0000 - val_loss: 749219.4375 - val_mae: 749219.4375\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 26ms/sample - loss: 749221.0625 - mae: 749221.0625 - val_loss: 727367.3750 - val_mae: 727367.3750\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 27ms/sample - loss: 727369.3125 - mae: 727369.3125 - val_loss: 705560.5000 - val_mae: 705560.5000\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 2s 443ms/sample - loss: 243670.0938 - mae: 243670.0938 - val_loss: 166229.6875 - val_mae: 166229.6875\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 26ms/sample - loss: 166230.3125 - mae: 166230.3125 - val_loss: 89288.2812 - val_mae: 89288.2812\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 26ms/sample - loss: 89289.0312 - mae: 89289.0312 - val_loss: 19249.6758 - val_mae: 19249.6758\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 1s 366ms/sample - loss: 34967.8203 - mae: 34967.8203 - val_loss: 27444.2461 - val_mae: 27444.2461\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 25ms/sample - loss: 27445.0469 - mae: 27445.0469 - val_loss: 25433.9766 - val_mae: 25433.9766\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 25ms/sample - loss: 25434.1035 - mae: 25434.1035 - val_loss: 22124.5176 - val_mae: 22124.5176\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 2s 395ms/sample - loss: 534988.5625 - mae: 534988.5625 - val_loss: 480599.5312 - val_mae: 480599.5312\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 26ms/sample - loss: 480600.5000 - mae: 480600.5000 - val_loss: 426522.4375 - val_mae: 426522.4375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 29ms/sample - loss: 426523.5938 - mae: 426523.5938 - val_loss: 372607.4375 - val_mae: 372607.4375\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 2s 386ms/sample - loss: 555802.5625 - mae: 555802.5625 - val_loss: 491675.0625 - val_mae: 491675.0625\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 27ms/sample - loss: 491676.4688 - mae: 491676.4688 - val_loss: 427470.3750 - val_mae: 427470.3750\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 29ms/sample - loss: 427472.0000 - mae: 427472.0000 - val_loss: 363288.0938 - val_mae: 363288.0938\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 2s 466ms/sample - loss: 531569.0000 - mae: 531569.0000 - val_loss: 468770.0625 - val_mae: 468770.0625\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 38ms/sample - loss: 468773.1250 - mae: 468773.1250 - val_loss: 406489.4062 - val_mae: 406489.4062\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 28ms/sample - loss: 406492.0000 - mae: 406492.0000 - val_loss: 392130.8438 - val_mae: 392130.8438\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 2s 509ms/sample - loss: 330250.3750 - mae: 330250.3750 - val_loss: 253398.8438 - val_mae: 253398.8438\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 26ms/sample - loss: 253397.6250 - mae: 253397.6250 - val_loss: 177171.4844 - val_mae: 177171.4844\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 28ms/sample - loss: 177170.4375 - mae: 177170.4375 - val_loss: 102812.0469 - val_mae: 102812.0469\n",
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 2s 576ms/sample - loss: 146333.2344 - mae: 146333.2344 - val_loss: 102039.9844 - val_mae: 102039.9844\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 29ms/sample - loss: 102040.0078 - mae: 102040.0078 - val_loss: 58483.2773 - val_mae: 58483.2773\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 35ms/sample - loss: 58483.6719 - mae: 58483.6719 - val_loss: 47529.6953 - val_mae: 47529.6953\n"
     ]
    }
   ],
   "source": [
    "results = train_DNN(float_df, 5, 11, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "node"
    ]
   },
   "outputs": [],
   "source": [
    "def mae_convergence(dataframe, n_splits, n_calls):\n",
    "\n",
    "    # x values\n",
    "    x = np.linspace(1, n_calls, n_calls)\n",
    "\n",
    "    # y values\n",
    "    mae = [dataframe.loc[dataframe.iloc[:, 0] == fold, 'MAE (kcal/mol)'].cummin()\n",
    "           for fold in range(1, n_splits + 1)]\n",
    "    cumm_mae = list(zip(*mae))\n",
    "    y = [statistics.mean(call) for call in cumm_mae]\n",
    "\n",
    "    # standard devation\n",
    "    std = [statistics.stdev(call) for call in cumm_mae]\n",
    "\n",
    "    # standard devation bounds\n",
    "    y1 = [i - sd for i, sd in zip(y, std)]\n",
    "    y2 = [i + sd for i, sd in zip(y, std)]\n",
    "\n",
    "    # plot mean line\n",
    "    fig, ax = plt.subplots(figsize=[8, 6])\n",
    "    for axis in ['top','bottom','left','right']: ax.spines[axis].set_linewidth(2)\n",
    "\n",
    "    ax.plot(x, y,\n",
    "            color='green',\n",
    "            linewidth=2,\n",
    "            label='Average MAE over {} folds'.format(n_splits))\n",
    "\n",
    "    # plot standard deviation fill bounds\n",
    "    ax.fill_between(x, y1, y2,\n",
    "                    fc='lightsteelblue',\n",
    "                    ec='lightsteelblue',\n",
    "                    label='Standard deviation')\n",
    "\n",
    "    ax.set_xlabel('Number of calls $n$', fontsize=18)\n",
    "    ax.set_ylabel('MAE / kcal mol$^{-1}$', fontsize=18)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=18)\n",
    "\n",
    "    ax.legend(fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    fig.savefig('convergence_plot.png')\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a3d297c10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mae_logger = [[fold_num + 1, x] for fold_num, result in enumerate(results) for x in result['func_vals']]\n",
    "mae_df = pd.DataFrame(mae_logger, columns=['Fold', 'MAE (kcal/mol)'])\n",
    "mae_convergence(mae_df,5 , 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_convergence(all_models, n_calls):\n",
    "    \n",
    "    mae_logger = [[fold_num + 1, x] for fold_num, result in enumerate(all_models) for x in result['func_vals']]\n",
    "    mae_df = pd.DataFrame(mae_logger, columns=['Fold', 'MAE (kcal/mol)'])\n",
    "    \n",
    "    # x values\n",
    "    x = np.linspace(1, n_calls, n_calls)\n",
    "\n",
    "    # y values\n",
    "    mae = [mae_df.loc[mae_df.iloc[:, 0] == fold, 'MAE (kcal/mol)'].cummin()\n",
    "           for fold in range(1, n_splits + 1)]\n",
    "    cumm_mae = list(zip(*mae))\n",
    "    y = [statistics.mean(call) for call in cumm_mae]\n",
    "\n",
    "    # standard devation\n",
    "    std = [statistics.stdev(call) for call in cumm_mae]\n",
    "\n",
    "    # standard devation bounds\n",
    "    y1 = [i - sd for i, sd in zip(y, std)]\n",
    "    y2 = [i + sd for i, sd in zip(y, std)]\n",
    "\n",
    "    # plot mean line\n",
    "    fig, ax = plt.subplots(figsize=[8, 6])\n",
    "    for axis in ['top','bottom','left','right']: ax.spines[axis].set_linewidth(2)\n",
    "\n",
    "    ax.plot(x, y,\n",
    "            color='green',\n",
    "            linewidth=2,\n",
    "            label='Average MAE over {} folds'.format(n_splits))\n",
    "\n",
    "    # plot standard deviation fill bounds\n",
    "    ax.fill_between(x, y1, y2,\n",
    "                    fc='lightsteelblue',\n",
    "                    ec='lightsteelblue',\n",
    "                    label='Standard deviation')\n",
    "\n",
    "    ax.set_xlabel('Number of calls $n$', fontsize=18)\n",
    "    ax.set_ylabel('MAE / kcal mol$^{-1}$', fontsize=18)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=18)\n",
    "\n",
    "    ax.legend(fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    fig.savefig('convergence_plot.png')\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_calls' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-706132e53731>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_convergence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-a95b4373a44f>\u001b[0m in \u001b[0;36mplot_convergence\u001b[0;34m(all_models)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# x values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_calls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_calls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# y values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n_calls' is not defined"
     ]
    }
   ],
   "source": [
    "plot = plot_convergence(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Death cases</th>\n",
       "      <th>Infected cases</th>\n",
       "      <th>Period of time (months)</th>\n",
       "      <th>Population density inhab/km3</th>\n",
       "      <th>Population</th>\n",
       "      <th>GDP (trillion USD)</th>\n",
       "      <th>Infected rate</th>\n",
       "      <th>Mortality rate</th>\n",
       "      <th>Temperature C (1st month)</th>\n",
       "      <th>Humidity %(1st month)</th>\n",
       "      <th>Epidemic or not</th>\n",
       "      <th>Epidemic or no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2002 SARS China</td>\n",
       "      <td>774.0</td>\n",
       "      <td>8090.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1128.0</td>\n",
       "      <td>8392000.0</td>\n",
       "      <td>1471.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>9.57</td>\n",
       "      <td>19.4</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>784.0</td>\n",
       "      <td>8100.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8392010.0</td>\n",
       "      <td>1481.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>19.57</td>\n",
       "      <td>29.4</td>\n",
       "      <td>74.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>784.0</td>\n",
       "      <td>8100.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8392010.0</td>\n",
       "      <td>1481.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>19.57</td>\n",
       "      <td>29.4</td>\n",
       "      <td>74.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>784.0</td>\n",
       "      <td>8100.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8392010.0</td>\n",
       "      <td>1481.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>19.57</td>\n",
       "      <td>29.4</td>\n",
       "      <td>74.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>784.0</td>\n",
       "      <td>8100.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8392010.0</td>\n",
       "      <td>1481.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>19.57</td>\n",
       "      <td>29.4</td>\n",
       "      <td>74.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Death cases  Infected cases  Period of time (months)  \\\n",
       "2002 SARS China        774.0          8090.0                      8.0   \n",
       "0                      784.0          8100.0                     18.0   \n",
       "0                      784.0          8100.0                     18.0   \n",
       "0                      784.0          8100.0                     18.0   \n",
       "0                      784.0          8100.0                     18.0   \n",
       "\n",
       "                 Population density inhab/km3  Population  GDP (trillion USD)  \\\n",
       "2002 SARS China                        1128.0   8392000.0              1471.0   \n",
       "0                                      1138.0   8392010.0              1481.0   \n",
       "0                                      1138.0   8392010.0              1481.0   \n",
       "0                                      1138.0   8392010.0              1481.0   \n",
       "0                                      1138.0   8392010.0              1481.0   \n",
       "\n",
       "                 Infected rate  Mortality rate  Temperature C (1st month)  \\\n",
       "2002 SARS China            0.1            9.57                       19.4   \n",
       "0                         10.1           19.57                       29.4   \n",
       "0                         10.1           19.57                       29.4   \n",
       "0                         10.1           19.57                       29.4   \n",
       "0                         10.1           19.57                       29.4   \n",
       "\n",
       "                 Humidity %(1st month)  Epidemic or not  Epidemic or no  \n",
       "2002 SARS China                   64.0              1.0             1.0  \n",
       "0                                 74.0             11.0             1.0  \n",
       "0                                 74.0             11.0             0.0  \n",
       "0                                 74.0             11.0             1.0  \n",
       "0                                 74.0             11.0             0.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X = np.asarray([x + 10 for x in float_df.iloc[-1,:-1]])\n",
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(model_num, test_entry):\n",
    "    \"\"\"Load model from HDF5 and return model prediction on a given test_entry.\"\"\"\n",
    "\n",
    "    model = tf.keras.models.load_model('/Users/wilsonwu/OUTBRAIK/outbraik/data/06_models/fold_' + str(model_num) + '_model.h5')\n",
    "\n",
    "    return model.predict(test_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_input to have shape (11,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-23a176bc688d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_rst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-7c0661df5a25>\u001b[0m in \u001b[0;36mmodel_predict\u001b[0;34m(model_num, test_entry)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/wilsonwu/OUTBRAIK/outbraik/data/06_models/fold_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_num\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_entry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/freesolv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/freesolv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m     return self._model_iteration(\n\u001b[1;32m    461\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         steps=steps, callbacks=callbacks, **kwargs)\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/freesolv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m           \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m           distribution_strategy=strategy)\n\u001b[0m\u001b[1;32m    397\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/freesolv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         steps=steps)\n\u001b[0m\u001b[1;32m    595\u001b[0m   adapter = adapter_cls(\n\u001b[1;32m    596\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/freesolv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2470\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2472\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/freesolv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    572\u001b[0m                              \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m                              str(data_shape))\n\u001b[0m\u001b[1;32m    575\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_input to have shape (11,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "test_rst = model_predict(1, test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predict_per_fold = [model_predict(fold_num, test_X.to_numpy()) for fold_num in range(1, n_splits + 1)]\n",
    "predict_per_fold = [np.asarray([x[0] for x in fold.tolist()]) for fold in predict_per_fold]\n",
    "predicted_y = pd.DataFrame(data={'Average predicted dGhydr (kcal/mol)': [float(x) for x in np.average(predict_per_fold, axis=0)],\n",
    "                                      'Standard deviation (kcal/mol)': np.std(predict_per_fold, axis=0)},\n",
    "                           index=test_ID)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
