{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#Dummy-data\" data-toc-modified-id=\"Dummy-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Dummy data</a></span></li><li><span><a href=\"#Cross-validation\" data-toc-modified-id=\"Cross-validation-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Cross-validation</a></span></li><li><span><a href=\"#Create-Tensorflow-DNN-model\" data-toc-modified-id=\"Create-Tensorflow-DNN-model-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Create Tensorflow DNN model</a></span></li><li><span><a href=\"#Bayesian-optimisation\" data-toc-modified-id=\"Bayesian-optimisation-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Bayesian optimisation</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nodos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wilsonwu/anaconda3/envs/freesolv/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# General:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import time\n",
    "import shutil\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "# Tensorflow:\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Scikit-Optimise\n",
    "from skopt import gp_minimize, dump\n",
    "from skopt.space import Categorical, Integer\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "# Statistics:\n",
    "import scipy\n",
    "from uncertainties import unumpy\n",
    "import itertools\n",
    "import statistics\n",
    "itertools.imap = lambda *args, **kwargs: list(map(*args, **kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Death cases</th>\n",
       "      <th>Infected cases</th>\n",
       "      <th>Period of time (months)</th>\n",
       "      <th>Population density inhab/km2</th>\n",
       "      <th>Population</th>\n",
       "      <th>GDP (trillion USD)</th>\n",
       "      <th>Infection rate</th>\n",
       "      <th>Incidence rate (of 1000 people-month)</th>\n",
       "      <th>Air traffic</th>\n",
       "      <th>Temperature C (1st month)</th>\n",
       "      <th>Humidity %(1st month)</th>\n",
       "      <th>Mortality rate</th>\n",
       "      <th>Epidemic or not</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disease</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2019 Novel Coronavirus</td>\n",
       "      <td>724.0</td>\n",
       "      <td>34964.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1304.50</td>\n",
       "      <td>11081000.0</td>\n",
       "      <td>12.24</td>\n",
       "      <td>0.32</td>\n",
       "      <td>157.77</td>\n",
       "      <td>24500346.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2.07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2002 SARS China</td>\n",
       "      <td>774.0</td>\n",
       "      <td>8090.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1128.00</td>\n",
       "      <td>8392000.0</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.10</td>\n",
       "      <td>12.05</td>\n",
       "      <td>16014411.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>64.0</td>\n",
       "      <td>9.57</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2008 HFMD China</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1884.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.47</td>\n",
       "      <td>728000.0</td>\n",
       "      <td>4.60</td>\n",
       "      <td>0.26</td>\n",
       "      <td>258.79</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>79.3</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2009 Influenza Mexico</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4174.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>111.14</td>\n",
       "      <td>8000000.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.05</td>\n",
       "      <td>52.18</td>\n",
       "      <td>1586101.0</td>\n",
       "      <td>22.1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.92</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2012 MERS Saudi Arabia</td>\n",
       "      <td>449.0</td>\n",
       "      <td>1123.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2295.63</td>\n",
       "      <td>3673000.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.85</td>\n",
       "      <td>21565000.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>39.98</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2015 Influenza India</td>\n",
       "      <td>2035.0</td>\n",
       "      <td>33761.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>214.68</td>\n",
       "      <td>73471198.0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>11.49</td>\n",
       "      <td>2887195.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>6.03</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019 Measles Samoa</td>\n",
       "      <td>83.0</td>\n",
       "      <td>5707.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64.83</td>\n",
       "      <td>196440.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.91</td>\n",
       "      <td>726.30</td>\n",
       "      <td>137770.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.45</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019 Measles Tonga</td>\n",
       "      <td>0.0</td>\n",
       "      <td>612.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>144.47</td>\n",
       "      <td>108137.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>188.65</td>\n",
       "      <td>62500.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019 Measles Rep. Of the Congo</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8745.77</td>\n",
       "      <td>2308000.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10.83</td>\n",
       "      <td>773.71</td>\n",
       "      <td>627753.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018 HFMD Malaysia</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1323.45</td>\n",
       "      <td>570407.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.77</td>\n",
       "      <td>1095.71</td>\n",
       "      <td>5564722.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2017 Pneumonic Plague Madagascar</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1618.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>198.00</td>\n",
       "      <td>3349000.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>16.10</td>\n",
       "      <td>366000.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>4.45</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000 Measles in Ireland</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1376.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3108.61</td>\n",
       "      <td>988540.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.14</td>\n",
       "      <td>19.89</td>\n",
       "      <td>12000000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2002 Influenza Madagascar</td>\n",
       "      <td>156.0</td>\n",
       "      <td>1291.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1876.74</td>\n",
       "      <td>161494.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>799.41</td>\n",
       "      <td>31000.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>80.0</td>\n",
       "      <td>12.08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019 MERS Qatar</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4858.94</td>\n",
       "      <td>641380.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>38780000.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Death cases  Infected cases  \\\n",
       "Disease                                                         \n",
       "2019 Novel Coronavirus                  724.0         34964.0   \n",
       "2002 SARS China                         774.0          8090.0   \n",
       "2008 HFMD China                          20.0          1884.0   \n",
       "2009 Influenza Mexico                    80.0          4174.0   \n",
       "2012 MERS Saudi Arabia                  449.0          1123.0   \n",
       "2015 Influenza India                   2035.0         33761.0   \n",
       "2019 Measles Samoa                       83.0          5707.0   \n",
       "2019 Measles Tonga                        0.0           612.0   \n",
       "2019 Measles Rep. Of the Congo         6000.0        250000.0   \n",
       "2018 HFMD Malaysia                        2.0         50000.0   \n",
       "2017 Pneumonic Plague Madagascar         72.0          1618.0   \n",
       "2000 Measles in Ireland                   2.0          1376.0   \n",
       "2002 Influenza Madagascar               156.0          1291.0   \n",
       "2019 MERS Qatar                           0.0             3.0   \n",
       "\n",
       "                                  Period of time (months)  \\\n",
       "Disease                                                     \n",
       "2019 Novel Coronavirus                                2.0   \n",
       "2002 SARS China                                       8.0   \n",
       "2008 HFMD China                                       1.0   \n",
       "2009 Influenza Mexico                                 1.0   \n",
       "2012 MERS Saudi Arabia                               36.0   \n",
       "2015 Influenza India                                  4.0   \n",
       "2019 Measles Samoa                                    4.0   \n",
       "2019 Measles Tonga                                    3.0   \n",
       "2019 Measles Rep. Of the Congo                       14.0   \n",
       "2018 HFMD Malaysia                                    8.0   \n",
       "2017 Pneumonic Plague Madagascar                      3.0   \n",
       "2000 Measles in Ireland                               7.0   \n",
       "2002 Influenza Madagascar                             1.0   \n",
       "2019 MERS Qatar                                       0.5   \n",
       "\n",
       "                                  Population density inhab/km2  Population  \\\n",
       "Disease                                                                      \n",
       "2019 Novel Coronavirus                                 1304.50  11081000.0   \n",
       "2002 SARS China                                        1128.00   8392000.0   \n",
       "2008 HFMD China                                          74.47    728000.0   \n",
       "2009 Influenza Mexico                                   111.14   8000000.0   \n",
       "2012 MERS Saudi Arabia                                 2295.63   3673000.0   \n",
       "2015 Influenza India                                    214.68  73471198.0   \n",
       "2019 Measles Samoa                                       64.83    196440.0   \n",
       "2019 Measles Tonga                                      144.47    108137.0   \n",
       "2019 Measles Rep. Of the Congo                         8745.77   2308000.0   \n",
       "2018 HFMD Malaysia                                     1323.45    570407.0   \n",
       "2017 Pneumonic Plague Madagascar                        198.00   3349000.0   \n",
       "2000 Measles in Ireland                                3108.61    988540.0   \n",
       "2002 Influenza Madagascar                              1876.74    161494.0   \n",
       "2019 MERS Qatar                                        4858.94    641380.0   \n",
       "\n",
       "                                  GDP (trillion USD)  Infection rate  \\\n",
       "Disease                                                                \n",
       "2019 Novel Coronavirus                         12.24            0.32   \n",
       "2002 SARS China                                 1.47            0.10   \n",
       "2008 HFMD China                                 4.60            0.26   \n",
       "2009 Influenza Mexico                           0.90            0.05   \n",
       "2012 MERS Saudi Arabia                          0.73            0.03   \n",
       "2015 Influenza India                            2.10            0.05   \n",
       "2019 Measles Samoa                              0.00            2.91   \n",
       "2019 Measles Tonga                              0.00            0.57   \n",
       "2019 Measles Rep. Of the Congo                  0.01           10.83   \n",
       "2018 HFMD Malaysia                              0.36            8.77   \n",
       "2017 Pneumonic Plague Madagascar                0.01            0.05   \n",
       "2000 Measles in Ireland                         0.10            0.14   \n",
       "2002 Influenza Madagascar                       0.00            0.80   \n",
       "2019 MERS Qatar                                 0.19            0.00   \n",
       "\n",
       "                                  Incidence rate (of 1000 people-month)  \\\n",
       "Disease                                                                   \n",
       "2019 Novel Coronavirus                                           157.77   \n",
       "2002 SARS China                                                   12.05   \n",
       "2008 HFMD China                                                  258.79   \n",
       "2009 Influenza Mexico                                             52.18   \n",
       "2012 MERS Saudi Arabia                                             0.85   \n",
       "2015 Influenza India                                              11.49   \n",
       "2019 Measles Samoa                                               726.30   \n",
       "2019 Measles Tonga                                               188.65   \n",
       "2019 Measles Rep. Of the Congo                                   773.71   \n",
       "2018 HFMD Malaysia                                              1095.71   \n",
       "2017 Pneumonic Plague Madagascar                                  16.10   \n",
       "2000 Measles in Ireland                                           19.89   \n",
       "2002 Influenza Madagascar                                        799.41   \n",
       "2019 MERS Qatar                                                    0.94   \n",
       "\n",
       "                                  Air traffic  Temperature C (1st month)  \\\n",
       "Disease                                                                    \n",
       "2019 Novel Coronavirus             24500346.0                        8.0   \n",
       "2002 SARS China                    16014411.0                       19.4   \n",
       "2008 HFMD China                      250000.0                        9.2   \n",
       "2009 Influenza Mexico               1586101.0                       22.1   \n",
       "2012 MERS Saudi Arabia             21565000.0                       32.0   \n",
       "2015 Influenza India                2887195.0                       21.0   \n",
       "2019 Measles Samoa                   137770.0                       30.0   \n",
       "2019 Measles Tonga                    62500.0                       26.0   \n",
       "2019 Measles Rep. Of the Congo       627753.0                       27.0   \n",
       "2018 HFMD Malaysia                  5564722.0                       26.0   \n",
       "2017 Pneumonic Plague Madagascar     366000.0                       16.0   \n",
       "2000 Measles in Ireland            12000000.0                        5.0   \n",
       "2002 Influenza Madagascar             31000.0                       14.4   \n",
       "2019 MERS Qatar                    38780000.0                       26.0   \n",
       "\n",
       "                                  Humidity %(1st month)  Mortality rate  \\\n",
       "Disease                                                                   \n",
       "2019 Novel Coronavirus                             71.0            2.07   \n",
       "2002 SARS China                                    64.0            9.57   \n",
       "2008 HFMD China                                    79.3            1.06   \n",
       "2009 Influenza Mexico                              80.0            1.92   \n",
       "2012 MERS Saudi Arabia                             56.0           39.98   \n",
       "2015 Influenza India                               46.0            6.03   \n",
       "2019 Measles Samoa                                 75.0            1.45   \n",
       "2019 Measles Tonga                                 77.0            0.00   \n",
       "2019 Measles Rep. Of the Congo                     80.0            2.40   \n",
       "2018 HFMD Malaysia                                 88.0            0.00   \n",
       "2017 Pneumonic Plague Madagascar                   84.0            4.45   \n",
       "2000 Measles in Ireland                            85.0            0.15   \n",
       "2002 Influenza Madagascar                          80.0           12.08   \n",
       "2019 MERS Qatar                                    54.0            0.00   \n",
       "\n",
       "                                  Epidemic or not  \n",
       "Disease                                            \n",
       "2019 Novel Coronavirus                        1.0  \n",
       "2002 SARS China                               1.0  \n",
       "2008 HFMD China                               1.0  \n",
       "2009 Influenza Mexico                         1.0  \n",
       "2012 MERS Saudi Arabia                        1.0  \n",
       "2015 Influenza India                          1.0  \n",
       "2019 Measles Samoa                            1.0  \n",
       "2019 Measles Tonga                            1.0  \n",
       "2019 Measles Rep. Of the Congo                1.0  \n",
       "2018 HFMD Malaysia                            0.0  \n",
       "2017 Pneumonic Plague Madagascar              0.0  \n",
       "2000 Measles in Ireland                       0.0  \n",
       "2002 Influenza Madagascar                     0.0  \n",
       "2019 MERS Qatar                               0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv('~/OUTBRAIK/dataset.csv', index_col='Disease').drop('Region', axis=1)\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Death cases</th>\n",
       "      <th>Infected cases</th>\n",
       "      <th>Period of time (months)</th>\n",
       "      <th>Population density inhab/km2</th>\n",
       "      <th>Population</th>\n",
       "      <th>GDP (trillion USD)</th>\n",
       "      <th>Infection rate</th>\n",
       "      <th>Incidence rate (of 1000 people-month)</th>\n",
       "      <th>Air traffic</th>\n",
       "      <th>Temperature C (1st month)</th>\n",
       "      <th>Humidity %(1st month)</th>\n",
       "      <th>Mortality rate</th>\n",
       "      <th>Epidemic or not</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disease</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2012 MERS Saudi Arabia</td>\n",
       "      <td>449.0</td>\n",
       "      <td>1123.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2295.63</td>\n",
       "      <td>3673000.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.85</td>\n",
       "      <td>21565000.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>39.98</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2015 Influenza India</td>\n",
       "      <td>2035.0</td>\n",
       "      <td>33761.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>214.68</td>\n",
       "      <td>73471198.0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>11.49</td>\n",
       "      <td>2887195.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>6.03</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019 Measles Samoa</td>\n",
       "      <td>83.0</td>\n",
       "      <td>5707.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64.83</td>\n",
       "      <td>196440.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.91</td>\n",
       "      <td>726.30</td>\n",
       "      <td>137770.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.45</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019 Measles Tonga</td>\n",
       "      <td>0.0</td>\n",
       "      <td>612.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>144.47</td>\n",
       "      <td>108137.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>188.65</td>\n",
       "      <td>62500.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000 Measles in Ireland</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1376.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3108.61</td>\n",
       "      <td>988540.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.14</td>\n",
       "      <td>19.89</td>\n",
       "      <td>12000000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2017 Pneumonic Plague Madagascar</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1618.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>198.00</td>\n",
       "      <td>3349000.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>16.10</td>\n",
       "      <td>366000.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>4.45</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019 Novel Coronavirus</td>\n",
       "      <td>724.0</td>\n",
       "      <td>34964.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1304.50</td>\n",
       "      <td>11081000.0</td>\n",
       "      <td>12.24</td>\n",
       "      <td>0.32</td>\n",
       "      <td>157.77</td>\n",
       "      <td>24500346.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2.07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019 Measles Rep. Of the Congo</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8745.77</td>\n",
       "      <td>2308000.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10.83</td>\n",
       "      <td>773.71</td>\n",
       "      <td>627753.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2002 Influenza Madagascar</td>\n",
       "      <td>156.0</td>\n",
       "      <td>1291.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1876.74</td>\n",
       "      <td>161494.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>799.41</td>\n",
       "      <td>31000.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>80.0</td>\n",
       "      <td>12.08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018 HFMD Malaysia</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1323.45</td>\n",
       "      <td>570407.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.77</td>\n",
       "      <td>1095.71</td>\n",
       "      <td>5564722.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019 MERS Qatar</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4858.94</td>\n",
       "      <td>641380.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>38780000.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2009 Influenza Mexico</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4174.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>111.14</td>\n",
       "      <td>8000000.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.05</td>\n",
       "      <td>52.18</td>\n",
       "      <td>1586101.0</td>\n",
       "      <td>22.1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.92</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2008 HFMD China</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1884.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.47</td>\n",
       "      <td>728000.0</td>\n",
       "      <td>4.60</td>\n",
       "      <td>0.26</td>\n",
       "      <td>258.79</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>79.3</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2002 SARS China</td>\n",
       "      <td>774.0</td>\n",
       "      <td>8090.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1128.00</td>\n",
       "      <td>8392000.0</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.10</td>\n",
       "      <td>12.05</td>\n",
       "      <td>16014411.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>64.0</td>\n",
       "      <td>9.57</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Death cases  Infected cases  \\\n",
       "Disease                                                         \n",
       "2012 MERS Saudi Arabia                  449.0          1123.0   \n",
       "2015 Influenza India                   2035.0         33761.0   \n",
       "2019 Measles Samoa                       83.0          5707.0   \n",
       "2019 Measles Tonga                        0.0           612.0   \n",
       "2000 Measles in Ireland                   2.0          1376.0   \n",
       "2017 Pneumonic Plague Madagascar         72.0          1618.0   \n",
       "2019 Novel Coronavirus                  724.0         34964.0   \n",
       "2019 Measles Rep. Of the Congo         6000.0        250000.0   \n",
       "2002 Influenza Madagascar               156.0          1291.0   \n",
       "2018 HFMD Malaysia                        2.0         50000.0   \n",
       "2019 MERS Qatar                           0.0             3.0   \n",
       "2009 Influenza Mexico                    80.0          4174.0   \n",
       "2008 HFMD China                          20.0          1884.0   \n",
       "2002 SARS China                         774.0          8090.0   \n",
       "\n",
       "                                  Period of time (months)  \\\n",
       "Disease                                                     \n",
       "2012 MERS Saudi Arabia                               36.0   \n",
       "2015 Influenza India                                  4.0   \n",
       "2019 Measles Samoa                                    4.0   \n",
       "2019 Measles Tonga                                    3.0   \n",
       "2000 Measles in Ireland                               7.0   \n",
       "2017 Pneumonic Plague Madagascar                      3.0   \n",
       "2019 Novel Coronavirus                                2.0   \n",
       "2019 Measles Rep. Of the Congo                       14.0   \n",
       "2002 Influenza Madagascar                             1.0   \n",
       "2018 HFMD Malaysia                                    8.0   \n",
       "2019 MERS Qatar                                       0.5   \n",
       "2009 Influenza Mexico                                 1.0   \n",
       "2008 HFMD China                                       1.0   \n",
       "2002 SARS China                                       8.0   \n",
       "\n",
       "                                  Population density inhab/km2  Population  \\\n",
       "Disease                                                                      \n",
       "2012 MERS Saudi Arabia                                 2295.63   3673000.0   \n",
       "2015 Influenza India                                    214.68  73471198.0   \n",
       "2019 Measles Samoa                                       64.83    196440.0   \n",
       "2019 Measles Tonga                                      144.47    108137.0   \n",
       "2000 Measles in Ireland                                3108.61    988540.0   \n",
       "2017 Pneumonic Plague Madagascar                        198.00   3349000.0   \n",
       "2019 Novel Coronavirus                                 1304.50  11081000.0   \n",
       "2019 Measles Rep. Of the Congo                         8745.77   2308000.0   \n",
       "2002 Influenza Madagascar                              1876.74    161494.0   \n",
       "2018 HFMD Malaysia                                     1323.45    570407.0   \n",
       "2019 MERS Qatar                                        4858.94    641380.0   \n",
       "2009 Influenza Mexico                                   111.14   8000000.0   \n",
       "2008 HFMD China                                          74.47    728000.0   \n",
       "2002 SARS China                                        1128.00   8392000.0   \n",
       "\n",
       "                                  GDP (trillion USD)  Infection rate  \\\n",
       "Disease                                                                \n",
       "2012 MERS Saudi Arabia                          0.73            0.03   \n",
       "2015 Influenza India                            2.10            0.05   \n",
       "2019 Measles Samoa                              0.00            2.91   \n",
       "2019 Measles Tonga                              0.00            0.57   \n",
       "2000 Measles in Ireland                         0.10            0.14   \n",
       "2017 Pneumonic Plague Madagascar                0.01            0.05   \n",
       "2019 Novel Coronavirus                         12.24            0.32   \n",
       "2019 Measles Rep. Of the Congo                  0.01           10.83   \n",
       "2002 Influenza Madagascar                       0.00            0.80   \n",
       "2018 HFMD Malaysia                              0.36            8.77   \n",
       "2019 MERS Qatar                                 0.19            0.00   \n",
       "2009 Influenza Mexico                           0.90            0.05   \n",
       "2008 HFMD China                                 4.60            0.26   \n",
       "2002 SARS China                                 1.47            0.10   \n",
       "\n",
       "                                  Incidence rate (of 1000 people-month)  \\\n",
       "Disease                                                                   \n",
       "2012 MERS Saudi Arabia                                             0.85   \n",
       "2015 Influenza India                                              11.49   \n",
       "2019 Measles Samoa                                               726.30   \n",
       "2019 Measles Tonga                                               188.65   \n",
       "2000 Measles in Ireland                                           19.89   \n",
       "2017 Pneumonic Plague Madagascar                                  16.10   \n",
       "2019 Novel Coronavirus                                           157.77   \n",
       "2019 Measles Rep. Of the Congo                                   773.71   \n",
       "2002 Influenza Madagascar                                        799.41   \n",
       "2018 HFMD Malaysia                                              1095.71   \n",
       "2019 MERS Qatar                                                    0.94   \n",
       "2009 Influenza Mexico                                             52.18   \n",
       "2008 HFMD China                                                  258.79   \n",
       "2002 SARS China                                                   12.05   \n",
       "\n",
       "                                  Air traffic  Temperature C (1st month)  \\\n",
       "Disease                                                                    \n",
       "2012 MERS Saudi Arabia             21565000.0                       32.0   \n",
       "2015 Influenza India                2887195.0                       21.0   \n",
       "2019 Measles Samoa                   137770.0                       30.0   \n",
       "2019 Measles Tonga                    62500.0                       26.0   \n",
       "2000 Measles in Ireland            12000000.0                        5.0   \n",
       "2017 Pneumonic Plague Madagascar     366000.0                       16.0   \n",
       "2019 Novel Coronavirus             24500346.0                        8.0   \n",
       "2019 Measles Rep. Of the Congo       627753.0                       27.0   \n",
       "2002 Influenza Madagascar             31000.0                       14.4   \n",
       "2018 HFMD Malaysia                  5564722.0                       26.0   \n",
       "2019 MERS Qatar                    38780000.0                       26.0   \n",
       "2009 Influenza Mexico               1586101.0                       22.1   \n",
       "2008 HFMD China                      250000.0                        9.2   \n",
       "2002 SARS China                    16014411.0                       19.4   \n",
       "\n",
       "                                  Humidity %(1st month)  Mortality rate  \\\n",
       "Disease                                                                   \n",
       "2012 MERS Saudi Arabia                             56.0           39.98   \n",
       "2015 Influenza India                               46.0            6.03   \n",
       "2019 Measles Samoa                                 75.0            1.45   \n",
       "2019 Measles Tonga                                 77.0            0.00   \n",
       "2000 Measles in Ireland                            85.0            0.15   \n",
       "2017 Pneumonic Plague Madagascar                   84.0            4.45   \n",
       "2019 Novel Coronavirus                             71.0            2.07   \n",
       "2019 Measles Rep. Of the Congo                     80.0            2.40   \n",
       "2002 Influenza Madagascar                          80.0           12.08   \n",
       "2018 HFMD Malaysia                                 88.0            0.00   \n",
       "2019 MERS Qatar                                    54.0            0.00   \n",
       "2009 Influenza Mexico                              80.0            1.92   \n",
       "2008 HFMD China                                    79.3            1.06   \n",
       "2002 SARS China                                    64.0            9.57   \n",
       "\n",
       "                                  Epidemic or not  \n",
       "Disease                                            \n",
       "2012 MERS Saudi Arabia                        1.0  \n",
       "2015 Influenza India                          1.0  \n",
       "2019 Measles Samoa                            1.0  \n",
       "2019 Measles Tonga                            1.0  \n",
       "2000 Measles in Ireland                       0.0  \n",
       "2017 Pneumonic Plague Madagascar              0.0  \n",
       "2019 Novel Coronavirus                        1.0  \n",
       "2019 Measles Rep. Of the Congo                1.0  \n",
       "2002 Influenza Madagascar                     0.0  \n",
       "2018 HFMD Malaysia                            0.0  \n",
       "2019 MERS Qatar                               0.0  \n",
       "2009 Influenza Mexico                         1.0  \n",
       "2008 HFMD China                               1.0  \n",
       "2002 SARS China                               1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled = raw_data.sample(frac=1)\n",
    "shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = shuffled.iloc[:10,:]\n",
    "test_set = shuffled.iloc[10:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "node"
    ]
   },
   "outputs": [],
   "source": [
    "def split_dataset(dataframe, n_splits):\n",
    "    \"\"\"Scikit-Learn KFold implementation for pandas DataFrame.\"\"\"\n",
    "\n",
    "    label_col = 'Epidemic or not'\n",
    "    random_state = 2\n",
    "    \n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    kfolds = []\n",
    "\n",
    "    for train, validate in kf.split(dataframe):\n",
    "        training = dataframe.iloc[train]\n",
    "        train_labels = training[label_col]\n",
    "        train_set = training.drop(label_col, axis=1)\n",
    "\n",
    "        validating = dataframe.iloc[validate]\n",
    "        validate_labels = validating[label_col]\n",
    "        validate_set = validating.drop(label_col, axis=1)\n",
    "\n",
    "        kfolds.append(\n",
    "            [[train_set, validate_set],\n",
    "             [train_labels, validate_labels]]\n",
    "        )\n",
    "\n",
    "    with open('/Users/wilsonwu/OUTBRAIK/outbraik/data/06_models/kfolds.json', \"wb\") as file:\n",
    "        pickle.dump(kfolds, file)\n",
    "\n",
    "    logging.info('Pickled kfolds nested list to JSON.')\n",
    "    return kfolds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tensorflow DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "node"
    ]
   },
   "outputs": [],
   "source": [
    "def create_model(num_dense_layers_base, num_dense_nodes_base,\n",
    "                 num_dense_layers_end, num_dense_nodes_end,\n",
    "                 activation, adam_b1, adam_b2, adam_eps):\n",
    "    \n",
    "    num_input_nodes = 12\n",
    "    \n",
    "    # Craete linear stack of layers.\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # Define input layer.\n",
    "    model.add(keras.layers.Dense(\n",
    "        num_input_nodes,  # N.umber of nodes\n",
    "        input_shape=(num_input_nodes,)  # Tuple specifying data input dimensions only needed in first layer.\n",
    "             ))\n",
    "\n",
    "    # Define n number of hidden layers (base, i.e. first layers).\n",
    "    for i in range(num_dense_layers_base):\n",
    "        model.add(keras.layers.Dense(\n",
    "            num_dense_nodes_base,\n",
    "            activation=activation\n",
    "        ))\n",
    "\n",
    "    # Define n number of hidden layers (end, i.e. last layers).\n",
    "    for i in range(num_dense_layers_end):\n",
    "        model.add(keras.layers.Dense(\n",
    "            num_dense_nodes_end,\n",
    "            activation=activation\n",
    "        ))\n",
    "\n",
    "    # Add two output nodes.\n",
    "    model.add(keras.layers.Dense(1, activation=keras.activations.linear))\n",
    "    \n",
    "    model.add(keras.layers.Activation('sigmoid'))\n",
    "\n",
    "    # Define dam optimiser.\n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "        lr=0.0001,  # Learning rate\n",
    "        beta_1=adam_b1,  # Exponential decay rate for the first moment estimates.\n",
    "        beta_2=adam_b2,  # Exponential decay rate for the second-moment estimates.\n",
    "        epsilon=adam_eps  # Prevent any division by zero.\n",
    "    )\n",
    "\n",
    "    # Compile model.\n",
    "    model.compile(\n",
    "        loss='mae',  # Loss function\n",
    "        optimizer=optimizer,  # Optimisaion function defined above.\n",
    "        metrics=['mae']  # Metric to be recorded.\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "node"
    ]
   },
   "outputs": [],
   "source": [
    "def train_model(fold, fold_num, n_calls, epochs):\n",
    "    \"\"\"\n",
    "    1. Unpack training data.\n",
    "    2. Define hyper-perameter ranges.\n",
    "    3. Define early stopping perameters.\n",
    "    4. Optimise hyper-perameters and save best model.\n",
    "    5. Save mae per call to CSV.\n",
    "    \"\"\"\n",
    "    logging.info('Training fold {}.'.format(str(fold_num)))\n",
    "    \n",
    "    # Retrieve data sets and convert to numpy array.\n",
    "    train_X = fold[0][0].values\n",
    "    validate_X = fold[0][1].values\n",
    "    train_y = fold[1][0].values\n",
    "    validate_y = fold[1][1].values\n",
    "\n",
    "    # Define hyper-perameters.\n",
    "    # Layers\n",
    "    dim_num_dense_layers_base = Integer(low=1, high=2, name='num_dense_layers_base')\n",
    "    dim_num_dense_nodes_base = Categorical(categories=list(np.linspace(5, 261, 10, dtype=int)),\n",
    "                                           name='num_dense_nodes_base')\n",
    "    dim_num_dense_layers_end = Integer(low=1, high=2, name='num_dense_layers_end')\n",
    "    dim_num_dense_nodes_end = Categorical(categories=list(np.linspace(5, 261, 10, dtype=int)),\n",
    "                                          name='num_dense_nodes_end')\n",
    "\n",
    "    # Optimiser\n",
    "    dim_adam_b1 = Categorical(categories=list(np.linspace(0.8, 0.99, 11)), name='adam_b1')\n",
    "    dim_adam_b2 = Categorical(categories=list(np.linspace(0.8, 0.99, 11)), name='adam_b2')\n",
    "    dim_adam_eps = Categorical(categories=list(np.linspace(0.0001, 0.5, 11)), name='adam_eps')\n",
    "\n",
    "    dimensions = [dim_num_dense_layers_base, dim_num_dense_nodes_base,\n",
    "                  dim_num_dense_layers_end, dim_num_dense_nodes_end,\n",
    "                  dim_adam_b1, dim_adam_b2, dim_adam_eps]\n",
    "\n",
    "    # Set early stopping variable to prevent overfitting.\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',  # Monitor validation loss\n",
    "        mode='min',  # Monitoring loss\n",
    "        patience=20,  # Large patience for small batch size\n",
    "        verbose=0)  # Do not output to terminal\n",
    "\n",
    "    best_mae = np.inf\n",
    "    \n",
    "    # Start hyper-perameter optimisation.\n",
    "    @use_named_args(dimensions=dimensions)\n",
    "    def fitness(num_dense_layers_base, num_dense_nodes_base,\n",
    "                num_dense_layers_end, num_dense_nodes_end,\n",
    "                adam_b1, adam_b2, adam_eps):\n",
    "\n",
    "        # Create the neural network with these hyper-parameters.\n",
    "        model = create_model(num_dense_layers_base=num_dense_layers_base,\n",
    "                             num_dense_nodes_base=num_dense_nodes_base,\n",
    "                             num_dense_layers_end=num_dense_layers_end,\n",
    "                             num_dense_nodes_end=num_dense_nodes_end,\n",
    "                             activation=tf.keras.activations.relu,\n",
    "                             adam_b1=adam_b1, adam_b2=adam_b2, adam_eps=adam_eps)\n",
    "\n",
    "        history = model.fit(train_X, train_y, # Training data\n",
    "                            epochs=epochs,  # Number of forward and backward runs.\n",
    "                            validation_data=(validate_X, validate_y),  # Validation data\n",
    "                            verbose=1,\n",
    "                            callbacks=[early_stopping],  # Prevent overfitting.\n",
    "                            batch_size=30)  # Increase efficiency\n",
    "\n",
    "        mae = history.history['val_mae'][-1]\n",
    "        # If the regressor accuracy of the saved model is improved...\n",
    "        nonlocal  best_mae\n",
    "        if mae < best_mae:\n",
    "            # Save the new model to harddisk.\n",
    "            model.save('/Users/wilsonwu/OUTBRAIK/outbraik/data/06_models/fold_' + str(fold_num) + '_model.h5')\n",
    "            # Update the regressor accuracy.\n",
    "            best_mae = mae\n",
    "\n",
    "        # Delete the Keras model with these hyper-parameters from memory.\n",
    "        del model\n",
    "\n",
    "        # Clear the Keras session, otherwise it will keep adding new\n",
    "        # models to the same TensorFlow graph each time we create\n",
    "        # a model with a different set of hyper-parameters.\n",
    "        K.clear_session()\n",
    "\n",
    "        # Reset best MAE.\n",
    "        best_mae = np.inf\n",
    "\n",
    "        return mae\n",
    "\n",
    "    # A place for optimiser to start looking.\n",
    "    default_parameters = [2, 261, 1, 61, 0.857, 0.933, 0.20006]\n",
    "\n",
    "    search_result = gp_minimize(func=fitness,\n",
    "                                dimensions=dimensions,\n",
    "                                acq_func='EI',  # Expected Improvement\n",
    "                                n_calls=n_calls,\n",
    "                                x0=default_parameters)\n",
    "\n",
    "    # Save skopt object.\n",
    "    dump(search_result,\n",
    "         '/Users/wilsonwu/OUTBRAIK/outbraik/data/06_models/fold_' + str(fold_num) +  '_gp_minimize_result.pickle',\n",
    "         store_objective=False)\n",
    "    logging.info('Pickled fold {} Scikit-Optimise object.'.format(fold_num))\n",
    "\n",
    "    logging.info('Fold {} final parameters: {}.'.format(str(fold_num), search_result.x))\n",
    "    return search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "node"
    ]
   },
   "outputs": [],
   "source": [
    "def train_DNN(dataframe, n_splits, n_calls, epochs):\n",
    "    \n",
    "    kfolds = split_dataset(dataframe, n_splits)\n",
    "    all_models = [train_model(fold, fold_num+1, n_calls, epochs) for fold_num, fold in enumerate(kfolds)]\n",
    "\n",
    "    return all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 2s 231ms/sample - loss: 0.6250 - mae: 0.6250 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 13ms/sample - loss: 0.6250 - mae: 0.6250 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 13ms/sample - loss: 0.6250 - mae: 0.6250 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 2s 193ms/sample - loss: 0.3750 - mae: 0.3750 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 12ms/sample - loss: 0.3750 - mae: 0.3750 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 13ms/sample - loss: 0.3750 - mae: 0.3750 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 2s 214ms/sample - loss: 0.3750 - mae: 0.3750 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 12ms/sample - loss: 0.3750 - mae: 0.3750 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 13ms/sample - loss: 0.3750 - mae: 0.3750 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 2s 210ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 12ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 14ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 2s 193ms/sample - loss: 0.3750 - mae: 0.3750 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 9ms/sample - loss: 0.3750 - mae: 0.3750 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 9ms/sample - loss: 0.3750 - mae: 0.3750 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 1s 171ms/sample - loss: 0.3750 - mae: 0.3750 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 9ms/sample - loss: 0.3750 - mae: 0.3750 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 9ms/sample - loss: 0.3750 - mae: 0.3750 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 2s 228ms/sample - loss: 0.3750 - mae: 0.3750 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 43ms/sample - loss: 0.3750 - mae: 0.3750 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 22ms/sample - loss: 0.3750 - mae: 0.3750 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 2s 201ms/sample - loss: 0.6250 - mae: 0.6250 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 12ms/sample - loss: 0.6250 - mae: 0.6250 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 13ms/sample - loss: 0.6250 - mae: 0.6250 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 2s 247ms/sample - loss: 0.3750 - mae: 0.3750 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 14ms/sample - loss: 0.3750 - mae: 0.3750 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 13ms/sample - loss: 0.3750 - mae: 0.3750 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 2s 209ms/sample - loss: 0.3750 - mae: 0.3750 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 12ms/sample - loss: 0.3750 - mae: 0.3750 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 13ms/sample - loss: 0.3750 - mae: 0.3750 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 1s 178ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 12ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 12ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 1s 176ms/sample - loss: 0.6250 - mae: 0.6250 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 12ms/sample - loss: 0.6250 - mae: 0.6250 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 13ms/sample - loss: 0.6250 - mae: 0.6250 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 1s 168ms/sample - loss: 0.3750 - mae: 0.3750 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 9ms/sample - loss: 0.3750 - mae: 0.3750 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 11ms/sample - loss: 0.3750 - mae: 0.3750 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 2s 212ms/sample - loss: 0.7500 - mae: 0.7500 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 13ms/sample - loss: 0.7500 - mae: 0.7500 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 14ms/sample - loss: 0.7500 - mae: 0.7500 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 2s 188ms/sample - loss: 0.3750 - mae: 0.3750 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 9ms/sample - loss: 0.3750 - mae: 0.3750 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 9ms/sample - loss: 0.3750 - mae: 0.3750 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 1s 154ms/sample - loss: 0.3750 - mae: 0.3750 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 9ms/sample - loss: 0.3750 - mae: 0.3750 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 9ms/sample - loss: 0.3750 - mae: 0.3750 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 1s 182ms/sample - loss: 0.3750 - mae: 0.3750 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 11ms/sample - loss: 0.3750 - mae: 0.3750 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 13ms/sample - loss: 0.3750 - mae: 0.3750 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 1s 176ms/sample - loss: 0.3750 - mae: 0.3750 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 10ms/sample - loss: 0.3750 - mae: 0.3750 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 13ms/sample - loss: 0.3750 - mae: 0.3750 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 1s 181ms/sample - loss: 0.7500 - mae: 0.7500 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 12ms/sample - loss: 0.7500 - mae: 0.7500 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 12ms/sample - loss: 0.7500 - mae: 0.7500 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 2s 216ms/sample - loss: 0.2500 - mae: 0.2500 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 12ms/sample - loss: 0.2500 - mae: 0.2500 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 16ms/sample - loss: 0.2500 - mae: 0.2500 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 3s 421ms/sample - loss: 0.6250 - mae: 0.6250 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 29ms/sample - loss: 0.6250 - mae: 0.6250 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 16ms/sample - loss: 0.6250 - mae: 0.6250 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 3s 355ms/sample - loss: 0.6250 - mae: 0.6250 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 17ms/sample - loss: 0.6250 - mae: 0.6250 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 19ms/sample - loss: 0.6250 - mae: 0.6250 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 2s 194ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 13ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 15ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 2s 245ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 13ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 16ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 1s 186ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 14ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 15ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 2s 209ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 10ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 11ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 2s 196ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 13ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 15ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 2s 197ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 13ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 15ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 1s 180ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 13ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 14ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 1s 161ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 12ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 14ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 3s 344ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 13ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 15ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 2s 207ms/sample - loss: 0.6250 - mae: 0.6250 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 13ms/sample - loss: 0.6250 - mae: 0.6250 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 14ms/sample - loss: 0.6250 - mae: 0.6250 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 2s 210ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 12ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 12ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 2s 194ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 13ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 13ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 2s 218ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 13ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 13ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 1s 152ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 9ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 9ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 2s 308ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 23ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 29ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 2s 293ms/sample - loss: 0.4375 - mae: 0.4375 - val_loss: 0.2500 - val_mae: 0.2500\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 15ms/sample - loss: 0.4375 - mae: 0.4375 - val_loss: 0.2500 - val_mae: 0.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 16ms/sample - loss: 0.4375 - mae: 0.4375 - val_loss: 0.2500 - val_mae: 0.2500\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 2s 232ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 13ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 13ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 2s 200ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 13ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 14ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 2s 220ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 12ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 14ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 2s 240ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 13ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 16ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 2s 247ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 12ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 13ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 2s 222ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 16ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 15ms/sample - loss: 0.5000 - mae: 0.5000 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 2s 230ms/sample - loss: 0.3750 - mae: 0.3750 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 17ms/sample - loss: 0.3750 - mae: 0.3750 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 20ms/sample - loss: 0.3750 - mae: 0.3750 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 3s 336ms/sample - loss: 0.7500 - mae: 0.7500 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 15ms/sample - loss: 0.7500 - mae: 0.7500 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 14ms/sample - loss: 0.7500 - mae: 0.7500 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 2s 280ms/sample - loss: 0.2500 - mae: 0.2500 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 11ms/sample - loss: 0.2500 - mae: 0.2500 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 10ms/sample - loss: 0.2500 - mae: 0.2500 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 2s 217ms/sample - loss: 0.6875 - mae: 0.6875 - val_loss: 0.7500 - val_mae: 0.7500\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 14ms/sample - loss: 0.6875 - mae: 0.6875 - val_loss: 0.7500 - val_mae: 0.7500\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 9ms/sample - loss: 0.6875 - mae: 0.6875 - val_loss: 0.7500 - val_mae: 0.7500\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 2s 246ms/sample - loss: 0.2500 - mae: 0.2500 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 10ms/sample - loss: 0.2500 - mae: 0.2500 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 9ms/sample - loss: 0.2500 - mae: 0.2500 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 2s 259ms/sample - loss: 0.7500 - mae: 0.7500 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 27ms/sample - loss: 0.7500 - mae: 0.7500 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 28ms/sample - loss: 0.7500 - mae: 0.7500 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 3s 378ms/sample - loss: 0.2500 - mae: 0.2500 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 18ms/sample - loss: 0.2500 - mae: 0.2500 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 14ms/sample - loss: 0.2500 - mae: 0.2500 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 1s 165ms/sample - loss: 0.7500 - mae: 0.7500 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 12ms/sample - loss: 0.7500 - mae: 0.7500 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 13ms/sample - loss: 0.7500 - mae: 0.7500 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 2s 188ms/sample - loss: 0.2500 - mae: 0.2500 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 11ms/sample - loss: 0.2500 - mae: 0.2500 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 13ms/sample - loss: 0.2500 - mae: 0.2500 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 1s 181ms/sample - loss: 0.3750 - mae: 0.3750 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 13ms/sample - loss: 0.3750 - mae: 0.3750 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 13ms/sample - loss: 0.3750 - mae: 0.3750 - val_loss: 0.5000 - val_mae: 0.5000\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 1s 185ms/sample - loss: 0.2500 - mae: 0.2500 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 14ms/sample - loss: 0.2500 - mae: 0.2500 - val_loss: 1.0000 - val_mae: 1.0000\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 10ms/sample - loss: 0.2500 - mae: 0.2500 - val_loss: 1.0000 - val_mae: 1.0000\n"
     ]
    }
   ],
   "source": [
    "results = train_DNN(train_set, 5, 11, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "node"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_convergence(all_models, n_splits, n_calls):\n",
    "    \n",
    "    mae_logger = [[fold_num + 1, x] for fold_num, result in enumerate(all_models) for x in result['func_vals']]\n",
    "    mae_df = pd.DataFrame(mae_logger, columns=['Fold', 'MAE (kcal/mol)'])\n",
    "    \n",
    "    # x values\n",
    "    x = np.linspace(1, n_calls, n_calls)\n",
    "\n",
    "    # y values\n",
    "    mae = [mae_df.loc[mae_df.iloc[:, 0] == fold, 'MAE (kcal/mol)'].cummin()\n",
    "           for fold in range(1, n_splits + 1)]\n",
    "    cumm_mae = list(zip(*mae))\n",
    "    y = [statistics.mean(call) for call in cumm_mae]\n",
    "\n",
    "    # standard devation\n",
    "    std = [statistics.stdev(call) for call in cumm_mae]\n",
    "\n",
    "    # standard devation bounds\n",
    "    y1 = [i - sd for i, sd in zip(y, std)]\n",
    "    y2 = [i + sd for i, sd in zip(y, std)]\n",
    "\n",
    "    # plot mean line\n",
    "    fig, ax = plt.subplots(figsize=[8, 6])\n",
    "    for axis in ['top','bottom','left','right']: ax.spines[axis].set_linewidth(2)\n",
    "\n",
    "    ax.plot(x, y,\n",
    "            color='green',\n",
    "            linewidth=2,\n",
    "            label='Average MAE over {} folds'.format(n_splits))\n",
    "\n",
    "    # plot standard deviation fill bounds\n",
    "    ax.fill_between(x, y1, y2,\n",
    "                    fc='lightsteelblue',\n",
    "                    ec='lightsteelblue',\n",
    "                    label='Standard deviation')\n",
    "\n",
    "    ax.set_xlabel('Number of calls $n$', fontsize=18)\n",
    "    ax.set_ylabel('MAE / kcal mol$^{-1}$', fontsize=18)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=18)\n",
    "\n",
    "    ax.legend(fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    fig.savefig('/Users/wilsonwu/OUTBRAIK/outbraik/data/08_reporting/convergence_plot.png')\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot = plot_convergence(results, 5, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test_set.iloc[:,:-1]\n",
    "test_y = test_set.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "node"
    ]
   },
   "outputs": [],
   "source": [
    "def model_predict(model_num, test_entry):\n",
    "    \"\"\"Load model from HDF5 and return model prediction on a given test_entry.\"\"\"\n",
    "\n",
    "    model = tf.keras.models.load_model('/Users/wilsonwu/OUTBRAIK/outbraik/data/06_models/fold_' + str(model_num) + '_model.h5')\n",
    "\n",
    "    return model.predict(test_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.]], dtype=float32), array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]], dtype=float32), array([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]], dtype=float32), array([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]], dtype=float32), array([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]], dtype=float32)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_splits = 5\n",
    "predict_per_fold = [model_predict(fold_num, test_X.to_numpy()) for fold_num in range(1, n_splits + 1)]\n",
    "predict_per_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Death cases</th>\n",
       "      <th>Infected cases</th>\n",
       "      <th>Period of time (months)</th>\n",
       "      <th>Population density inhab/km2</th>\n",
       "      <th>Population</th>\n",
       "      <th>GDP (trillion USD)</th>\n",
       "      <th>Infection rate</th>\n",
       "      <th>Incidence rate (of 1000 people-month)</th>\n",
       "      <th>Air traffic</th>\n",
       "      <th>Temperature C (1st month)</th>\n",
       "      <th>Humidity %(1st month)</th>\n",
       "      <th>Mortality rate</th>\n",
       "      <th>Epidemic or not</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disease</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2019 MERS Qatar</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4858.94</td>\n",
       "      <td>641380.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>38780000.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2009 Influenza Mexico</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4174.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>111.14</td>\n",
       "      <td>8000000.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.05</td>\n",
       "      <td>52.18</td>\n",
       "      <td>1586101.0</td>\n",
       "      <td>22.1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.92</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2008 HFMD China</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1884.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.47</td>\n",
       "      <td>728000.0</td>\n",
       "      <td>4.60</td>\n",
       "      <td>0.26</td>\n",
       "      <td>258.79</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>79.3</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2002 SARS China</td>\n",
       "      <td>774.0</td>\n",
       "      <td>8090.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1128.00</td>\n",
       "      <td>8392000.0</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.10</td>\n",
       "      <td>12.05</td>\n",
       "      <td>16014411.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>64.0</td>\n",
       "      <td>9.57</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Death cases  Infected cases  Period of time (months)  \\\n",
       "Disease                                                                       \n",
       "2019 MERS Qatar                0.0             3.0                      0.5   \n",
       "2009 Influenza Mexico         80.0          4174.0                      1.0   \n",
       "2008 HFMD China               20.0          1884.0                      1.0   \n",
       "2002 SARS China              774.0          8090.0                      8.0   \n",
       "\n",
       "                       Population density inhab/km2  Population  \\\n",
       "Disease                                                           \n",
       "2019 MERS Qatar                             4858.94    641380.0   \n",
       "2009 Influenza Mexico                        111.14   8000000.0   \n",
       "2008 HFMD China                               74.47    728000.0   \n",
       "2002 SARS China                             1128.00   8392000.0   \n",
       "\n",
       "                       GDP (trillion USD)  Infection rate  \\\n",
       "Disease                                                     \n",
       "2019 MERS Qatar                      0.19            0.00   \n",
       "2009 Influenza Mexico                0.90            0.05   \n",
       "2008 HFMD China                      4.60            0.26   \n",
       "2002 SARS China                      1.47            0.10   \n",
       "\n",
       "                       Incidence rate (of 1000 people-month)  Air traffic  \\\n",
       "Disease                                                                     \n",
       "2019 MERS Qatar                                         0.94   38780000.0   \n",
       "2009 Influenza Mexico                                  52.18    1586101.0   \n",
       "2008 HFMD China                                       258.79     250000.0   \n",
       "2002 SARS China                                        12.05   16014411.0   \n",
       "\n",
       "                       Temperature C (1st month)  Humidity %(1st month)  \\\n",
       "Disease                                                                   \n",
       "2019 MERS Qatar                             26.0                   54.0   \n",
       "2009 Influenza Mexico                       22.1                   80.0   \n",
       "2008 HFMD China                              9.2                   79.3   \n",
       "2002 SARS China                             19.4                   64.0   \n",
       "\n",
       "                       Mortality rate  Epidemic or not  \n",
       "Disease                                                 \n",
       "2019 MERS Qatar                  0.00              0.0  \n",
       "2009 Influenza Mexico            1.92              1.0  \n",
       "2008 HFMD China                  1.06              1.0  \n",
       "2002 SARS China                  9.57              1.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6]\n",
      " [0.8]\n",
      " [0.8]\n",
      " [0.6]]\n",
      "[0. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "predict_y = np.average(predict_per_fold, axis=0)\n",
    "print(predict_y)\n",
    "print(test_y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "node"
    ]
   },
   "outputs": [],
   "source": [
    "def model_predict(test_entry, n_splits):\n",
    "    \"\"\"Load model from HDF5 and return model prediction on a given test_entry.\"\"\"\n",
    "    \n",
    "    all_models = []\n",
    "    for fold_num in range(1, n_splits + 1):\n",
    "        model = tf.keras.models.load_model('/Users/wilsonwu/OUTBRAIK/outbraik/data/06_models/fold_' + str(fold_num) + '_model.h5')\n",
    "        all_models.append(model.predict(test_entry))\n",
    "    \n",
    "    results = [x[0] for x in all_models]\n",
    "    df = pd.DataFrame(results, columns=['Epidemic or no'])\n",
    "    df.to_csv('/Users/wilsonwu/OUTBRAIK/outbraik/data/07_model_output/output.csv')\n",
    "    \n",
    "    return all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_rst = model_predict(test_X.to_numpy(), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [x[0][0] for x in test_rst]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst_df = pd.read_csv('/Users/wilsonwu/OUTBRAIK/outbraik/data/07_model_output/output.csv')\n",
    "rst_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y.iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(test_y.values, [0.8, 0.8, 0.6, 0.8])"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
